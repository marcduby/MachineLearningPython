
20210318 - aiqc talk 
- look at 
  - docs.peewee-orm.com
  - flow forecast deep learning 
    - time series forecasting 
- https://github.com/AIStream-Peelout/flow-forecast


20201217 - pydate boston talks
- 20201217b - ML in cyber security

- 20201217a - pseudo label talk
  - data labeling is expensive
  - data is time consuming, but need it now
  - large diversity

- example: use image net, transfer learn, get pseuco labels, then use pseudo labels to retrain
  - to pretrain image net

- k fold cross validation
  - split into 5 sets, hold one back for validation
  - do this k times (hence the name)

- can use ensemble models to generate pseudo labels

- can try randomly flipping labels in the training (similar to dropout layer in NN for preventing overtraining)

- kaggle competition story
  - joined only 2 weeks before end
  - training data was from canada, private test data to judge model was from japan
    - so issues with overtrained data
  - added TTA (rotate, change brighteness) for images
    - multiple images per output
  - best is first trained on pseudo, then fine tuned on train data
    - so generate pseudo data
    - then start training from scratch on pseudo
    - then fine tune with smaller step size on train data 

- where not to use pseudo labeling
  - pseudo labeling accentuates a class imbalance (more of one class than another)
  - won't see much improvement where train and test similar

- sample kaggle notebook
  - https://www.kaggle.com/stanleyjzheng/exploring-pseudolabelling-schemes-pydata#



20201121 - pydata RI meetup - PySpark
- bryan cafferky
- hadoop
  - yarn: yet another resource coordinator
- spark is complete rethink and architecture of hadoop (100x performance improvement)
  - 4 parts (sql, mllib, streaming, graphx)
  - python not pre built in spark
    - community PySpark package wraps spark API
  - spark wants everyhting in memory as much as possible, then it will work on it
  - graph frames api replacing graphx 
  - databricks is a wrapper around spark 
-  RDD - resilient distributed dataset 
- spark api
  - load data for use by spark 
  - read manipulate data in spark
  - push processing to cluster nodes 
  - do work on head node 
- databricks demo
  - sc for spark context
  - spark 
  - more for sql (hive)
  - sqlContext (for hive)

- df methods
  - collect() -> force execution on all worker nodes and return data to head node 
  - printSchema() -> prints the schema 
  - describe()
  - head()
  - sample() 
  - toPandas()
  - groupBy()
  - agg()
  - plot() (might be only databricks)
  - 

- tiers for data work
  - 100 MB -> pandas and local VM
  - up to 30 TB -> sql db should be fine
  - 1 PB -> then spark, but see if you need all that data 




20201118 - pydata boston 
explaibale ML (XML)
- libraries used
  - lale for pipelines
  - use Hyperopt as opposed to GridSearch

BCI (brain computer interface)



20201115 - pydata global 2020 post mortem 
=========================================
- talks to review
  - day 5, building one multi task model to rul them all
    - moving models to production
  - day 5, coiled hosting dask
    - download coiled, test
  - day 5 - what lies in word embeddings 

- to do 
  - download coiled - coiled.io, dask.org
  - look at 



20201115 - pydata global 2020 day 5
===================================
1145 - building one multi task model
====================================
- for cobining fashion model for color and patterns
  - train on random batches of color or patterns
    - but only compute loss for that type of batches
- how to mve a jupyter model to production

- issues
  - when adding zseason feature to color/patterns
  - possible solutions
    - 3 models, one each for 
    - 2 models, one per task group 
    - one resnet per task but shared bert model 
    - one resent per task group, but shared bert model (chosen)

- open source library
  - github.com/ShopRunner/octopod
  - pypi.org/project/octopod 

1230 - hosting dask, challenges and opportunities
=================================================

1315 - what lies in word embeddings 
===================================
- ass opposed to embeddings words, do 3 letter embeddings 
  - so for university, do uni/niv/ive/ver/ers/rsi/sit/ity instead
  - helps with mispellings

- tools used
  - fasttext
  - bytepair
  - spacylanguage
  - huggingface
  - whatlies

20201114 - pydate global 2020
=============================
- look into 
  - prophet  model for time series

  

20201113 - pydata global 2020
=============================
1330 - parallel data processing
===============================
- 3 tools
  - spark, ray and dask

- look into
  - look at eric dill talk, 'is spark still relevant'
    - keith kraus 'high performance with rapids'
  - koalas (could use in spark)
  - mark garcia talk on dataframes (miami nyc meetup)
  - wrapping model.predict() in udd/udf block for spark

1700 - what's new in pandas
===========================
  - data.rolling(10).mean()
  - def udf(x):
    return x.mean()
    data.rolling(10).apply(udf, raw=True)
    data.rolling(10).apply(udf, raw=True, engine='numba')               # numba JIT compiler



    