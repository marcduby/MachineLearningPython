

architecture
------------
Method
    Stages (serial)
        Outputs/Job (parallel)
            Steps (can be parallel, usually serial)

create method 
-------------
- sbt new broadinstitute/dig-aggregator-method.g8

build aws/core
--------------
- sbt publishLocal
  - start with dig-aws, then do dig-aggregator-core


emr tips
--------
- copy bootstrap lookup files to 
  - WORK_DIR="/mnt/var/${JOB_METHOD}"

copy part files into one:
-------------------------
# download a common script for use
aws s3 cp "${JOB_BUCKET}/resources/scripts/getmerge-strip-headers.sh" .
chmod +x getmerge-strip-headers.sh
# download associations for this phenotype locally
./getmerge-strip-headers.sh "${OUT_DIR}/variant-associations/${PHENOTYPE}/part-*" ./associations.csv

worker setup
------------
- make dir and copy to /mnt/var/$JOB_METHOD/
  - aws s3 cp ..... <dest_dir>

- for resouyrces specified in stage class; they will be copied on deploy to ${JOB_BUCKET}/resources/${JOB_METHOD} bucket
  - aws s3 cp ${JOB_BUCKET}/resources/${JOB_METHOD}/fullBassetScript.py .

  - override def additionalResources = Seq(
        "fullBassetScript.py"
    )


how to run
-----------
- to test reprocess (no run due to no --yes)
  - sbt> run -c ../config.json --reprocess --only basset --clusters 10
  
- to include/exclude outputs
  - sbt> run -c ../config.json --reprocess --stage BassetStage --only T2D* --exclude *BMI

- to run in production, setting DRYRUN to true (basset only one stage, so fine)
  - sbt> run -c ../config.json --test --yes

- to run only one stage
  - run -c ../config.json --yes --stage MagmaCombineNcbiGenePValuesStage --reprocess

- update that these phenotypes ran (update aggregator db)
  - ./run.sh finemapping --stage RunCojoStage --insert-runs --only `cat /home/javaprog/Data/Broad/dig-analysis-data/out/finemapping/cojo.txt` --yes
  
- GIVES ERROR:
  - run -c ../config..json --reprocess --stage BurdenbinningStage

working runs:
-------------
  - run -c ../config.json --yes --stage PathwayAssociationsStage --only AD --reprocess
  - run -c ../config.json --yes --stage PathwayAssociationsStage --only 2hr* --reprocess

troubleshooting
---------------
- pyspark errors
  -> click process link
    -> summary
      -> look for folder icon
        -> containers
          -> applications
            -> stdout

monitoring:
-----------
- install htop
  - sudo yum install -y htop
- track steps that ran
  - aws s3 ls s3://dig-analysis-data/out/finemapping/cojo-results/ --recursive | awk -F '/' '{print $4}' | sort | uniq | xargs echo -n | sed -e "s/ /,/g" > cojo.txt
- run the steps and 

VM options:
-----------
  - Strategy.computeOptimized(vCPUs = 32) -> c5.9xlarge, 32 cpu, 72 gig
  - Strategy.memoryOptimized(mem = 128.gb) -> r5.4xlarge - 16 cpu, 128 gig
  - Ec2.Strategy.generalPurpose(mem = 64.gb) -> 


scratch:
--------

20200825 - cheatsheet
- sbt new broadinstitute/dig-aggregator-method.g8
- run --yes --only BioIndex/burden BioIndexProcessor

- aggregator tips
  - sbt> run --yes --only BioIndex/burden BioIndexProcessor

- setup
  - if have issues dig-aws
    - checkout dig-aws alongside aggregator
    - run 'sbt publishLocal' from that directory -> go to ivy
  - scala rebel console to play with
    - can start it from sbt, better to have your jars from the project in the classpath


Notes:
------
20210602 - the config.json has changed elements; use old one for now

    
Phenotype list:
---------------
https://bioindex-dev.hugeamp.org/api/portal/phenotypes

GraphQL queries:
----------------
query {
    GeneAssociations(gene: "PPARG") {
        phenotype, gene, pValue
    }
}

query {
    GlobalAssociations(phenotype: "T2D") {
        phenotype, gene, pValue
    }
}

query {
  GeneFinder(phenotype: "MultipleSclerosis") {
        phenotype, gene, pValue
  }
}


Notes from clint:
-----------------
- questions 
  - how does db work, where contacted
  - how to start aggregator
  - 

- answers
  - regions data:
    - out/ldsc/regions/merged/
    - process part of bottom line; cg used to be own aggregator method, but got m,erged into bottomline 
  - removed methods:
    - https://github.com/broadinstitute/dig-aggregator-methods/tree/preserving-ldsc
  - database
    - keeps track of the what has been successfully run for what inmputs 
  - git repos:
    - aws: emr type code 
    - methods: methods 
    - aggregator core: application logic, franework 
  - serverless:
    - bioindex has option of indexing using aws lambda
    - node app that pushes code up serverless 
      - only publish if changes needed
    - bioindex can communicate with lambda on its won afterwards (server not needed)
      - run with 30 workers 
  - bioindex 
    - rebuilding 
      - 

- interview resources
  - https://leetcode.com/
  - https://www.hackerrank.com/
  - https://www.levels.fyi/?compare=Google,Facebook,Microsoft&track=Software%20Engineer#contribute-home
  - blind 
  - system ddesgin 
  - 
