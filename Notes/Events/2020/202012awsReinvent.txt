

to watch:
---------
- astra zeneca big data
- what's new in redshift
- virtualized trials
- novartis manufacturing
- healthcare accelerating transformation
- intelligent document processing
- bristol myers
- lake house redshift
- transform reseach env
- explore quantum computing
- ventilator production
- erickson covid
- superfans viewing experience
- smart vison industrial
- space in the cloud
- deepracer analysis tool
- amazon enhance customer experience 
- corrosion detection
- aws deepcomposer
- code breaking in the cloud
- smart recycle
- ai for email insights
- add image recognition to web app
- connected vehicle repair
- drone zone
- robo van gogh
- intelligent sleep assistant
- industrial predictive quality
- wind farm maintenence
- monetize machine learning
- mise en production sagemaker
- serverless ml inference
- jupyter notebooks in sagemaker
- bmw serverless analytics 
- choosing right instance for inference 
- mcdonald's customer surveys
- mlops sagemaker implementing
- strategies machine learnign at scale 
- data transformation resrvoir
- nfl computer vision
- deep dive graviton 2
- high throughput ad tech
- corrosion detection
- codebreaking machine vision'
- making healthcare personal 
- medical imaging machine learning
- serverless data lake
- train and tune ml sagemaker
- vw industrial cloud
dec 08
- billion parameter models
- inventory planning solutions forecast
dec 09
- sagemaker debugger
- sagemaker jumpstart
- near linear scaling dataparallel
- amazon forecast inventory planning
- amazon personalize fans
- capitol one health of applications
- smart vision for preventative industrial
- future space in the cloud
- large scale distributed training
- pge customer operational
- ai for cliniocal workflows
- roi of iot 
dec 10
- explainability machine learning
- serverless data preparation
- cloud observability career
- chosse right algorithm
- wildfire with 
- end workflows kubeflow
dec 11
- 



watched:
--------
20201220 - ML applications architectures
- steps for ml applications
  - data ingestion
  - data preparation
  - feature engineering
  - model training
  - model evaluation and tunjing
  - model deployment
  - model inference
  - model monitoring and retraining
- well architected framework
  - operational excellence
    - version ml inputs and model artifacts/weights 
    - autimated model deployment pipeline
    - continuously monitor and measure ML workloads
    - establish model retaining straegy
  - securoty
    - use api gateway to black list IPs, throttle service for scale
  - reliability
    - train once and deoloy to distributed env (api, app) or (dev, test and prod)
    - manage changes to model inputs through automation
  - performance efficiency
    - deploy and monitor model and system performance 
      - use sagemaker for model monitoring 
    - optimize compute for ML workloads
    - define latency and network bandwidth performance requirements
  - cost optimization
    - use managed services to reduce costs 
    - experment with small datasets
    - right size training and inference VMs

- links
  - https://d1.awsstatic.com/whitepapers/architecture/wellarchitected-Machine-Learning-Lens.pdf?did=wp_card&trk=wp_card
  - https://wellarchitectedlabs.com/
  - https://aws.amazon.com/architecture/
  - https://aws.amazon.com/solutions/
  


20201218 - detect ML model drift in production
- aws sagemaker
- what is the issue
  - sata drift 
    - could have divergence of data
    - get data drift and accuracy drift metrics
  - model could degrade over time 
    - need to retrain the model every so often
- data drift metrics
  - get mean and std dev for training data
    - when incoming data comes in, compare to data metrics
  - also keep eye out for missing values, bad categorical values
- model drift 
  - compare predictions to ground truth of what happened
  - metrics: precision, recall, accuracy 
    - can chart metics against baseline

- actions 
  - retrain model wih new training data
  - update model 

- demo 
  - data: grouplens.org/datasets/movielens/
  - xgboost model
  




20201210 - picking ML algorithms with sagemaker
- 17 algorithms available
  - text
    - discovering topics in text docs or clustering docs
      - lda (latent dir allocation), ntm (neural topic modeling)
    - text classification
      - blazing text
    - text embedding
      - object embeddings
    - machine translation, audio tokens
      - sequence to sequence
  - images (computer vision)
    - image classification, object detection (bounding boxes), semantic segmentation (which pixel belongs to what object type)
  - numbers
    - classification/regression
      - linear learner (linear classification for linearly seperable classes), 
      - knn (recover unstructured partitions of the space), 
      - xgboost, factorization machines 
    - dimensionality reduction, used in pre processing 
      - pca
    - identify structure in data (clustering)
      - k-means
    - C
      - xgboost, 
    - aws improvement on isolation forest algo, used in anomaly detection 
      - random cut forest
    - time series
      - deepAR, 
    - anomaly detection using ipv4 addresses
      - IP insights
    - recommendations
      - object2vec, factorization machines
- supports tf2, pytorch, mxnet, sklearn

- xgboost
  - trees created sequentially (so one after upon the results of the other)
  - for each tree the residual with respect t the actual target is computed and becomes the new tree's target
    - so next tree fits on the residuals 
    - can also fit on fiunction of the residuals to optimize for different metrics
  - each tree learns to improve on the previous trees' classification/regression mistakes
  - predictive performance increases over forests
  - scales well over dozens of cores 

- gradient boosting
  - use the residuals for the next model targets 

- random forests
  - do sub sampling of rows and columns for each tree
  - then average out results of all trees on inference 

- sagemaker can also use your own training/inference docker containers
  - will manage the lifecycle 
  
- tips 
  - use float16 for backward/foprward pass, but keep model weights at float32
    - faster but don't lose much accuracy
  - file streaming 
    with open(image_file. 'rb) as f:
      post_payload = bytearray(f.read())
  - for unbalanced dataset, use scale positive weight 








20201210 - novartis manufactiruing
- use ML to apply to vendor product catalogs
  - comaring beaker prices
  - ML model extracts property features from the text of the catalogs
  - display prominently to the lab purchaser

- auto replnishment for supplies using ML 
  - data lake and amazon forecast 


20201209 - roche data liquidity for personalized medicine
- based on data and analytics
- techniques
  - nlp, descriptive stats, ML, inferential stats, causal inference, pharmaco epidemiology
  - data lake

- results
  - can do faster trials with peronalized focus
- people
  - data scientists


20201208 - train DL model in large scale distributed mode 
- solve issue with model too big to load in one VM
  - get OOM errors (out of memory)


20201208 - aws life sciences use cases


20201208 - ML keynote

