

20201203 - neo4j model ml 
- notes
  - node embeddings of a graph
    - a way to reduce dimensionality of graph, avoiding sparse connection matrix
    - should be able to rebuild graph architecture
    - algorithms
      - fastRP
        - construct similarity matrix, then multiply with random projection
        - preserves distance of nodes
        - get dimensionality preserving lower dimensionality matrix
        - 75x faster than node2vec
        - add nodes, need to redo all embeddings
      - node2vec
        - for every node in graph, take random walk; train model to predict the connections
        - given values of hidden model layer
        - slow, so billion node graph is issue
        - add nodes, need to redo all embeddings
      - graphsage
        - predictove model, given node, predicts what embeddings could be 
        - samples nodes near any given node, using node properties
        - reduces loss function, builds model to be able to rebuild graph
        - uses GNN 
        - can generate new embeddings as nodes are added
  - what to use embeddings for
    - neighborhood predictions
    - classification
    - visualization

- https://github.com/AliciaFrame/GDS_Retail_Demo



20201202 - qcon - pytorch to production
- https://www.youtube.com/watch?v=EkELQw9tdWE
- https://qconnewyork.com/system/files/presentation-slides/jeff_smith_-_pytorch_qcon_ny_2019.pdf

- notes
  - modules
    - torch.data (datasets and dataoaders)
    - torch.vision -> data, models
    - torck.jit -> deploy graph to language neutral structure
    - torch.nn -> base
  - hyper parameter tuning
    - bayesopt
      - botorch.org
    - also look at
      - pytext
      - translate
      - horizon for RL
      - detectron
  - https://pytorch.org/ecosystem/
  

- saving/loading checkpoints
torch.save({
            'epoch': epoch,
            'model_state_dict': model.state_dict(),
            'optimizer_state_dict': optimizer.state_dict(),
            'loss': loss,
            ...
            }, PATH)

model = TheModelClass(*args, **kwargs)
optimizer = TheOptimizerClass(*args, **kwargs)

checkpoint = torch.load(PATH)
model.load_state_dict(checkpoint['model_state_dict'])
optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
epoch = checkpoint['epoch']
loss = checkpoint['loss']

model.eval()
# - or -
model.train()
