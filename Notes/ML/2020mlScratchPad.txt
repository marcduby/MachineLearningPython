




20221109 - pydata nyc 2022 
- prod architecture 
  - kubernetes is a coker container management system 
  - can use cluster ip service to ping individual pods
    - even if they hare a VM/IP 
  - how to expose kubernetes service to outside 
    - use nodeport service 
    - can set http request to any workers 
  - loadbalancer service creates a loadbaalncer outside kubernetes 
    - it balances across nodes/VM, not pods as kubernetes does 
  - knative serv ice 
    - does automatic scaling,, creates pods as needed 


- resources 
  - eatch kubernetes youtube video by honeypot 
  - alternatives to kubernetes 
    - mazos, swarm, dockerflow? 



20221109 - pydata nyc shopify ML 
- shopify system
  - catalog management
    - product categorization 
  - fraud protection
  - customer acquisition 
  - invetory
  - saless 
  - finance 
  - sales 
  - POS 
  - p

- models 
  - multi lingual bert for text 
  - mobilez net v2 

- model arch 
  = bert and mobilenet in parrallel
    - get text embeddings and image embeddings
  - feed both into perceptron layer 

- inference archticture 
  - cache the embeddings of text and images as they come through
  - then send to the next layer 
  - that way, can look up cache and don't need to run embeddings again 
  - get savings in computer time and VM perspective 

- how to measure performance and impact 
  - also measure how used by merchants 

- ml for custoemr acquisition 
  - go from product categories -> buyer pool -> audience set from ML -> ad platform 
  - use FB and Google ad, but treplace their targeting engines 

- attribute extraction for prodyucst
  - probelm: attributes are specific to product categhores 
  - had domain  experts annotatee product categories 

- 


20201223 - pipeline work
- wrote test pipeline script using CA housing data
  - standard scalar didn't help with R2 score 
  - pca useless as well, best R2 score with full features
  - there is a way to modify pipelines with 
    - new_pipeline = Pipeline(old_pipeline.steps[1..2])
    - new_pipeline = Pipeline(old_pipeline.steps[1] + old_pipeline.stape[3])

- todo
  - try pca with correlated features
    - script correlation, then determine best dim for pca

    
20200426 - Hamburg PyData meetup - surrogate models
import tensorflow as tf
from tensorflow.keras.layers import Input, Dense, AlphaDropout

num_features = 2
num_categories = 3

dropout = 0.4
selu_dropout_model = tf.keras.Sequential()
selu_dropout_model.add(Input(name='input', shape=(num_features,)))
selu_dropout_model.add(Dense(name='hidden1', units=500, activation='selu'))
selu_dropout_model.add(AlphaDropout(dropout))
selu_dropout_model.add(Dense(name='hidden2', units=250, activation='selu', kernel_initializer=tf.initializers.lecun_normal(random_seed)))
selu_dropout_model.add(AlphaDropout(dropout))
selu_dropout_model.add(Dense(name='output', units=num_categories, activation='softmax'))

selu_dropout_model.compile(loss='sparse_categorical_crossentropy',
             optimizer=tf.keras.optimizers.Adam(),
             metrics=['accuracy'])
             
- use surrogate model for explainability
- steps
  - use NN to train on training data
  - fit the model
  - then create rgularized data and predict
  - use that result set to train a decision tree
  - now can use decision tree to explain model, test parameters
  
- decision trees overfot but are good for explainability
- NN models are generalized but black boxes

- alphadropout layer -> keeps mean and variance of inputs to their original values
  - best if used with selu activation on the debse layers
  
- selu -> scaled exponential linear units

