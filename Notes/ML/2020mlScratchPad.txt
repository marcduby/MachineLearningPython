


20221112 - nyc exercise
- data
  - mon 11/07 - 65 row -> 65
  - tue 11/08 - 0 -> 65
  - wed 11/09 - 30 bike + 45 bike -> 140 
  - thu 11/10 - 30 bike + 45 bike  + 5 stair -> 220
  - fri 11/11 - 30 bike -> 250 


20221111 - pydata nyc 2022 - cool stuff to look at 
- check env from the causal inf talk 
  - https://github.com/ronikobrosly/pydata_nyc_2022/blob/main/check_environment.py




20221111 - pydata nyc 2022 - causal inference 
- 3 types of causal relationships 
  - cofounder 
    - a cofounder is a third variable to causes both the tratment and outcome 
      - always need to control 
    - ie: smoking leads to cancer and leads to coffee 
      - but if not take into account smoking, looks like coffee correlates with cancer 
    - ie: if correlation between ice cream sales and violent crime 
      - but hot weather is the cofounder, since it leads to oth ice creame and violent crime 
  - colliders (dont want to contriol for)
    - inverse of confounder 
    - if smoking is correlated to lung cancer 
      - collider is # sign days 
  - mediators (don't want to control for)
    - sits between treatment and outcome 
    - ie: cliical signs of lung damage 
      - if control for lung damage, will lose the causal rekationship between smoking and lung cancer 

- confounder 
  - need to condition for it 
    - can remove the data (bayes)
    - use a model 


- traditional variabe importance methods don't tell you anything about causality 
  - shap, permutation importance could be issue 
  - don't condition based on these metrics 

- assumptions of causal inference  
  - - temporarlity 
  - 

- g-computation 
  - also look nto propensity score matching 
  - want to avoid including collider vars in model vars that will be conditioned for 
  - as opposed to doing linear regression, can use xgboost for the model 
    - with LR, can get some information from the gradients for the causation effect 




20221111 - pydata nyc 2022 - serving pytirch models in production 
- walmart 
  - tf models used 
  - java shop, so serve models using JNI (java native interface)
  - wanted to use BERT in pytorch 

- data used 
  - amazon berkeley objects data 

- optimizing models for production 
  - port training optimization -> quantization 
    - store tensors at lower bit fp precision; reduce memorey and speed up
    - hardware in8 computations 2 to 4x  faster than fp32 computations 
    - ie
      model_int = torch.quantization.quantize_dynamic()
  - 



20221111 - pydata nyc 2022 - DL for time series analysis 
- codee 
  - https://www.kaggle.com/isaacmg/code

- gisttory of time series DL
  - 2015 - vanilla lstm
  - 2017 - GRUIs, DA-RNN 
  - 2019 - transformers 
  - 2020 - emergence of DNN 

- forecasting, trying to determine feature variable at a future time step 
- classification, trying to assign labell to sequence of time steps 
- time series analysis - assign 0/1 label to sequence of time steps 

- pan points 
  - how to incorporrate additional information 

- tikme series forecasting industry is fractureed 

- stack overflow q (igodfried)
  - training loss is NAN keran nn


- q/a session
  - need 50k rows for good 
  - got transformers, can spend days during hyperparameter searching 
  - harder to do transfer learning for time series NNs than for NLP 


20221111 - pydata nyc 2022 - dask tutorial 
- code 
  - https://github.com/mrocklin/dask-tutorial

- avocado forecast flow example 
  - https://www.kaggle.com/code/isaacmg/avocado-price-forecasting-with-flow-forecast-ff
  - use 4 past time steps to forecast one time step 
  - use https://wandb.ai/site for logging traiuning model logging 
    - can get figures of loss rate, etc 
- avocado GRU example, probabilistic model 
  - https://www.kaggle.com/code/isaacmg/probablistic-gru-avocado-price-forecast
- avocado multi region transaformer 
  - https://www.kaggle.com/code/isaacmg/multi-region-transformer


20221110 - pydata nyc interestimg for DCC

- prodyucst
  - DVC for data version control 




2022110 - pydata nyc 2022 - ML at scale for finances (quansight team)
- look at 
  - amd ROCM similar to nvidia CUDA 
  - dask kubernetes 

  
- gpu ecosystem 
  - pytorch, ttf, numba, dask, rapids, heavy.ai, cuDF, blazinfsql (deprecated for dasksql)

- lexssons
  - io ops from gpu to host very closeness_centrality- gpu expensive 
  - python cuda ecosystem is great 

- libs 
  - dask 
  - prefect data workflow orchestration tool 
  - argo workflows 
    - specifically for kubernetes?







20221110 - pydata nyc 2022 - data and model version control in drug discovery pipelines 
- barreto-ojeda, cyclica inc 

- numbers 
  - genomics, 25k genes
  - rna, transcriptomics 1m transcripts
  - protein, proteomics 20m protein (from alphafold)
    - also meta published 1m proteins 
  - metabolites, metabolomics 5k

- data 
  - low number of observations (samples), high number of varoables (feature)
    - ie: 1 sample can gtet 100 tumors 
    - very high dimensional data 
  - protocals are not always reproduceable 
  - research based data 
    - more data on hot topics 
  - complex biological data 
    - dissimilar (diverse format and contents)
    - imbaanced (more data for given featire)
    - redundnt
    - spares (lacks annotaTIONS)

- DVC (data version control)
  - open soruce, works with all github providers (github, gitlab, bitbucket)


- code 
  - pip list | grep dvc 

  - to display chem structure 
    import pandas as pd
    data = pd.read_csv('./data/initial_data.csv')
    data.head()
    from rdkit import Chem
    from rdkit.Chem.Draw import IPythonConsole
    IPythonConsole.drawOptions.addAtomIndices = True
    IPythonConsole.molSize = 400,400

    mol = Chem.MolFromSmiles(data['smiles'][1])
    mol
    import pubchempy as pcp

    id_ = pcp.get_compounds(data['smiles'][1], 'smiles')[0]
    id_.synonyms[0]


- dvs steps 
  - dvc add 
  - dvc dag -> will print dependencies 




20221110 - pydata nyc 2022 - workflow engines by sanjay from Akasa
- akasa company 
  - number 1 cause of bankruptcy is medical bills 
  - $266 billion is wasteful admin medical work
  - company tries to automate away this work

- use ML to automate tasks 

- two types of automation 
  - workflow automation 
    - move data from EHR to insurance UI 
    - read response from website UI 
    - update state of the claim in the EHR 
  - information extraction 

- saying in healthcare 
  - if you've seen one hospital, you've seen one hospital

- technical 
  - the workflow stes are async 
  - also not safe to redo steps if later step fials 
    - if 10 steps, if step 5 fails, then not necessarily safe to redo step 1 to 4 
  - do replayable workflow steps by havng the step issue a token for its request 
    - if restart from start, identical tokens will just return dayta from cache, not rerunning step 
  - steps implemented in fuctions that are decorated with @wolkflow.task 
    - the ecorator pushes the function onto a queue 
  - with workers getting workflow tasks from queue, never blocking 
    - workers pick up other tasks that are queued up while waiting for the other tasks to complete 


- AWS example
  - when starting an EC2 instance
    - create network int, EBS FS, etc





20221110 - pydata nyc 2022 - stitchfix feature engineering framework
- book
  - marshall goldsmith - what got you here won't get you there 

- https://github.com/stitchfix/hamilton

- hamulton framework
  - has a visualization plug in to view DAG it creates 
  - can run haliton on spark, dask, ray 



20221109 - pydata nyc 2022 - shiny fpr python 
- libs 
  - astropy -> for astronomy watchong  

- but what abput streamlit?
  - streamlit rexecutes verything each interaction
  - some clver caching 
  - great for simple or small apps 
  - moderately ambitious apps, becomes liability 

- shiny for ambitious apps 

- https://shiny.rstudio.com/py 


- https://github.com/jcheng5/PyDataNYC2022-demos





20221109 - pydata nyc 2022 - graph based ML ransomware detection 
- ransomware
  - phishing
  - software bugs 
  - brute force credential attack 

- $1.2 billion in 2021 vs $416 million in 2020
- conti group biggest actor, $25 million per attack 

- data
  - use 32 threads to encrypt 
    - speed over stealth 
  - ransomware will be in network for a month, so have 30 days to fix before issues 
  - once on computer, you can see what other accounts have beenused on that computer 
  - mysticpy - security tool developed by M$
  - usually with backup pivileges, priveled acct 
    - can start to do damge from here 

- examp,es 
  - irish healthcare 
    - $100 million cost to get back up
    - didn't pay ransom 
    - some peolle use pen/paper for 35 days 

- approach 
  - connect events as graph 
  - calculate centraility 

- code 
  i,port networkx as nx 
  g = nx.from_pandas_edgelist(df, source, target)
  nx.draw(g, ith_labels=True, font-size  1)
  nx.show()

  nx.closeness_centrality()

- Msticpy library 
  - productionize wityh streaming graph db -> surrealdb

- new surrealdb product to look at 

- recommendations 
  - multi factor auth 
  - identity na;ytics (acct creation, permissions)
  - response proces to security logging, monitoring, alerts 
  - patch management 
  - supply chain 












- met william, ex LMT worker, air force vet, philly based 
  - met matt, speaker, texas based 

20221109 - pydata nyc 2022 - westher impact models 
- why predict weather 
  - crops, stores, transportationm, aviation, predict product mix 
  - reduce utility downtime 
    - can schwedule crews ahead of time 

- data collection 
  - weayher observations 
  - infrastructure density 
  - seasonal foliage, vegetation

- feature engineering/feature creation 

- for utilities 
  - need to predict multip,e times as storm path is being updated 
  - model preedictas number of outt=ges predicted in the next 72 hours 
  - weather data is at 4x4 km granularity 

- for creating trai i g data 
  - outages rolled up for 244 hour 
  - aggregate weather for t24 hours 
  - use pyspark as engine 

- ,model features 
  - wind - max, avg, min, max wind gust, min wind gust 
  - precipitation, snow, ice - max , avg cumulative, ice, snow density 
  - tems - max, evg, avg wet bulb temp 
  - infrastcuture - length of line, ...

- problem 
  - data quality - hignh outages recorded past event 
    - due to maintenenece after strim, needed 
    - lag in outage report as people come back/get service back 
    - very common for big storms 
    - data confusing to model, so remove the long tail from model 
  - also if lots of outage but not weather related 
    - so not needed for model, so remove outage calls 
    - outage not weather deependent 
  - low outages, significant weather 
    - removed 

- outage data challenges 
  - wide range and sparsity 
  - extreme weatyher rarely happens, so sparse 

- models 
  - best model is random forest 
  - routine false alarm days measurement 
  - use pareto boundary analysis for model selection 
  - clients are mkre intersted in mdeium storm prediction than large storm prediction 

- explainning predicted oputtages 
  - shapley values (shap)
    - helps to determine what each feature contributes to the prediction 
    - need to remove correlated features before training 
      - or else SHAP test will be skewed 
  - local interpretable model agnostic explanations (LIME)
  - contrasctive analysis 
  - sensitivity analysis
  - tree analysis (to tune for tree depth)
    - to help identify the cause of overprediction 
    - remove events/training daya to created the bad tree predictions 

- scoring models using forecast weather data 
  - using pyspark to aggregate data for 24/48 and 72 hours 
  - PMML model 

- look up 
  - PMML model 
    - https://en.wikipedia.org/wiki/Predictive_Model_Markup_Language








20221109 - pydata nyc 2022 - ML system deployment with kubernetes
- prod architecture 
  - kubernetes is a coker container management system 
  - can use cluster ip service to ping individual pods
    - even if they hare a VM/IP 
  - how to expose kubernetes service to outside 
    - use nodeport service 
    - can set http request to any workers 
  - loadbalancer service creates a loadbaalncer outside kubernetes 
    - it balances across nodes/VM, not pods as kubernetes does 
  - knative serv ice 
    - does automatic scaling,, creates pods as needed 


- resources 
  - eatch kubernetes youtube video by honeypot 
  - alternatives to kubernetes 
    - mazos, swarm, dockerflow? 



20221109 - pydata nyc shopify ML 
- shopify system
  - catalog management
    - product categorization 
  - fraud protection
  - customer acquisition 
  - invetory
  - saless 
  - finance 
  - sales 
  - POS 
  - p

- models 
  - multi lingual bert for text 
  - mobilez net v2 

- model arch 
  = bert and mobilenet in parrallel
    - get text embeddings and image embeddings
  - feed both into perceptron layer 

- inference archticture 
  - cache the embeddings of text and images as they come through
  - then send to the next layer 
  - that way, can look up cache and don't need to run embeddings again 
  - get savings in computer time and VM perspective 

- how to measure performance and impact 
  - also measure how used by merchants 

- ml for custoemr acquisition 
  - go from product categories -> buyer pool -> audience set from ML -> ad platform 
  - use FB and Google ad, but treplace their targeting engines 

- attribute extraction for prodyucst
  - probelm: attributes are specific to product categhores 
  - had domain  experts annotatee product categories 

- 


20221107 - mit ml seminar
- with single cell assays
  - can measure
    - rna Seq 
    - atac seq
    - chromatin accessibility
    - chromatin 3d 
    - gene expression 
  - want toi translation/predict what other modlity of measurement will be 
    - ie: from gene expression and chromatin accessibility, predict atac seq 
  - for learning 
    - need measurements from same cell for training data 
      - most assays are destructive, so only get one reading per cell 
      - use non destructive assay

- auto encoder
  - get representation of batch effects and sequencing depth 
- peptides 
  - sequence of amino acids (10-15 size?)
  - get observed spectrum from mass spectometer for each peptide 
  - the order of the amino acids affects the mass spectrometer reading curve 
  - only 1.4% overlap in peptides between species 
    - ? -> research 
- for transformers in NLP 
  - learning pairwise relationships between words 
  - can we use that for spectrometer peaks 

- ml models for genetics mentionned
  - babel 2021 



20221027 - broadway - ml in clinical applications
- questions to use ML 
  - what are protective mech for disease in the genome (like pcsk9)
  - how well infer rna expression from dna
  - can we combine omics data to predict outcomes and mech insights 
  - can we discover all endophenotypes (like BMI types)

- misc 
  - if unfold DNA, should be 6 feet long 
  - BMI - ratio of weight to surface area 


20201223 - pipeline work
- wrote test pipeline script using CA housing data
  - standard scalar didn't help with R2 score 
  - pca useless as well, best R2 score with full features
  - there is a way to modify pipelines with 
    - new_pipeline = Pipeline(old_pipeline.steps[1..2])
    - new_pipeline = Pipeline(old_pipeline.steps[1] + old_pipeline.stape[3])

- todo
  - try pca with correlated features
    - script correlation, then determine best dim for pca

    
20200426 - Hamburg PyData meetup - surrogate models
import tensorflow as tf
from tensorflow.keras.layers import Input, Dense, AlphaDropout

num_features = 2
num_categories = 3

dropout = 0.4
selu_dropout_model = tf.keras.Sequential()
selu_dropout_model.add(Input(name='input', shape=(num_features,)))
selu_dropout_model.add(Dense(name='hidden1', units=500, activation='selu'))
selu_dropout_model.add(AlphaDropout(dropout))
selu_dropout_model.add(Dense(name='hidden2', units=250, activation='selu', kernel_initializer=tf.initializers.lecun_normal(random_seed)))
selu_dropout_model.add(AlphaDropout(dropout))
selu_dropout_model.add(Dense(name='output', units=num_categories, activation='softmax'))

selu_dropout_model.compile(loss='sparse_categorical_crossentropy',
             optimizer=tf.keras.optimizers.Adam(),
             metrics=['accuracy'])
             
- use surrogate model for explainability
- steps
  - use NN to train on training data
  - fit the model
  - then create rgularized data and predict
  - use that result set to train a decision tree
  - now can use decision tree to explain model, test parameters
  
- decision trees overfot but are good for explainability
- NN models are generalized but black boxes

- alphadropout layer -> keeps mean and variance of inputs to their original values
  - best if used with selu activation on the debse layers
  
- selu -> scaled exponential linear units

