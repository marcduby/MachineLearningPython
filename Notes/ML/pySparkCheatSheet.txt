

- describe
    df_export.printSchema()
    df_export.count()
    df_export.describe()
    df_export.show()

- data aggregation
    df_export.groupBy("chromosome").count().orderBy("chromosome").show(25, False)


- select subset of columns
    df_export = df_nonnull_load.select("dbSnp", 'chromosome', 'position')
    df.where(F.col("count").isNull()).show()


- split column into other columns
    split_col = pyspark.sql.functions.split(df['my_str_col'], '-')
    df = df.withColumn('NAME1', split_col.getItem(0))

- export data
    df.coalesce(1).write.csv('result.csv')              # one file

    df_export.write.mode('overwrite').csv(out_file)
    os.system("cat output/test/p* > output/test.csv")   # one file; will not work in distributed env

    df_export.write.mode('overwrite').option("delimiter", "\t").csv(out_dir)


    srcdir = '%s/variants/*/%s' % (s3dir, args.phenotype)
    outdir = '%s/out/metaanalysis/variants/%s' % (s3dir, args.phenotype)





-- scratch
    opts = argparse.ArgumentParser()
    opts.add_argument('phenotype')

