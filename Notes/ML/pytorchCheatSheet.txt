

- tensors
  - a_transpose = torch.transpose(a, 0, 1)   # switch dimensions 0 and 1
  - two_tensor = torch.unsqueeze(torch.transpose(tensor, 1, 2), 3)      # add extra dimension at dim 3
  - tensor_input = torch.unsqueeze(tensor, 3)                           # add extra dimension
  - tensor_input = torch.transpose(tensor_input, 1, 2)                  # flip 2 dimensions
  - tensor_input = tensor_input.to(torch.float)                         # cast to float32 type
  - tensor.dtype            # what type of data the tensor is (has to be same throughout)
  - tensor.shape
  - print("got 0,1 prediction {}".format(predictions[0,2].item()))

- run model
  - pretrained_model_reloaded_th.eval()


- describe model
  - model.parameters()
  - model_weights = pretrained_model_reloaded_th.state_dict()
  
  # Print model's state_dict
print("Model's state_dict:")
for param_tensor in model.state_dict():
    print(param_tensor, "\t", model.state_dict()[param_tensor].size())

# Print optimizer's state_dict
print("Optimizer's state_dict:")
for var_name in optimizer.state_dict():
    print(var_name, "\t", optimizer.state_dict()[var_name])
    
    
    
torch.save(model.state_dict(), PATH)
Load:

model = TheModelClass(*args, **kwargs)
model.load_state_dict(torch.load(PATH))
model.eval()


- Basset lessons
  - torchfile module provides torchfile.hashable_uniq_dict, with <>.model as torchfile.TorchObject
  - load_lua loads as torch.legacy.nn.Sequential; can save as *.pth, but unable to reload into pytorch 1.5.1
    - unclear how to call inference on legacy nn (get dimension issue)
  - convert_pytorch script
    - creates a model file; can run nference with 900bp 
  
- lua torch
  - from torch.utils.serialization import load_lua
  - model = load_lua('/Users/mduby/Data/Broad/Basset/Nasa/ampt2d_cnn_900_check.th', unknown_classes=True, long_size=8)
  - model = load_lua('ampt2d_cnn_900_check.th', unknown_classes=True, long_size=8)

  - th convert_checkpoint_gpu_to_cpu.lua -model ampt2d_cnn_900_best.th


Convert Nasa model:
-------------------
- used https://github.com/kipoi/models/blob/master/Basset/convert_Basset_to_pytorch.py to convert_Basset_to_pytorch  usign .th file
  - got error for dict conversion, but at least got model.py file for model architecture

- ran new model successfully with initial random model_weights

- use load_lua for weights extraction from .th file
print("model.modules is of type {}".format(type(model.modules)))
  for module in model.modules:
      print("({}) model name {} and type {} and weights {}".format(count, module, type(module), module))
      count = count + 1



