{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "TF version 2.1.0\nnumpy version 1.18.1\nEager mode:  True\nGPU is NOT AVAILABLE\n"
    }
   ],
   "source": [
    "# imports\n",
    "import tensorflow as tf \n",
    "import numpy as np \n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "print(\"TF version {}\".format(tf.__version__))\n",
    "print(\"numpy version {}\".format(np.__version__))\n",
    "print(\"Eager mode: \", tf.executing_eagerly())\n",
    "print(\"GPU is\", \"available\" if tf.config.experimental.list_physical_devices(\"GPU\") else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_validate(data_array, test_percent, validate_percent):\n",
    "    index = len(data_array)\n",
    "    print(\"the train max index is {}\".format(index))\n",
    "\n",
    "    # get the test/train split\n",
    "    index = int(index * test_percent)\n",
    "    train_data = data_array[:index]\n",
    "    test_data = data_array[index:]\n",
    "    print(\"the test split index is {}\".format(index))\n",
    "\n",
    "    # get the train/validate split\n",
    "    index = int(index * validate_percent)\n",
    "    validate_data = train_data[index:]\n",
    "    train_data = train_data[:index]\n",
    "    print(\"the validate split index is {}\".format(index))\n",
    "\n",
    "    # return\n",
    "    return train_data, test_data, validate_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "the keys are dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names']) and the df of type <class 'sklearn.utils.Bunch'>\n"
    }
   ],
   "source": [
    "# load the wine data\n",
    "wine_df = load_wine()\n",
    "\n",
    "print(\"the keys are {} and the df of type {}\".format(wine_df.keys(), type(wine_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "the full features are of type <class 'numpy.ndarray'> and shape (178, 13)\nthe full labels are of type <class 'numpy.ndarray'> and shape (178,)\n"
    }
   ],
   "source": [
    "# get the features and labels\n",
    "Xstart = wine_df.data\n",
    "ystart = wine_df.target\n",
    "\n",
    "print(\"the full features are of type {} and shape {}\".format(type(Xstart), Xstart.shape))\n",
    "print(\"the full labels are of type {} and shape {}\".format(type(ystart), ystart.shape))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get new shuffled data\n",
    "X, y = shuffle(Xstart, ystart, random_state = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "the first 10 of the data is [[1.356e+01 1.710e+00 2.310e+00 1.620e+01 1.170e+02 3.150e+00 3.290e+00\n  3.400e-01 2.340e+00 6.130e+00 9.500e-01 3.380e+00 7.950e+02]\n [1.377e+01 1.900e+00 2.680e+00 1.710e+01 1.150e+02 3.000e+00 2.790e+00\n  3.900e-01 1.680e+00 6.300e+00 1.130e+00 2.930e+00 1.375e+03]\n [1.351e+01 1.800e+00 2.650e+00 1.900e+01 1.100e+02 2.350e+00 2.530e+00\n  2.900e-01 1.540e+00 4.200e+00 1.100e+00 2.870e+00 1.095e+03]\n [1.161e+01 1.350e+00 2.700e+00 2.000e+01 9.400e+01 2.740e+00 2.920e+00\n  2.900e-01 2.490e+00 2.650e+00 9.600e-01 3.260e+00 6.800e+02]\n [1.348e+01 1.670e+00 2.640e+00 2.250e+01 8.900e+01 2.600e+00 1.100e+00\n  5.200e-01 2.290e+00 1.175e+01 5.700e-01 1.780e+00 6.200e+02]\n [1.285e+01 1.600e+00 2.520e+00 1.780e+01 9.500e+01 2.480e+00 2.370e+00\n  2.600e-01 1.460e+00 3.930e+00 1.090e+00 3.630e+00 1.015e+03]\n [1.438e+01 3.590e+00 2.280e+00 1.600e+01 1.020e+02 3.250e+00 3.170e+00\n  2.700e-01 2.190e+00 4.900e+00 1.040e+00 3.440e+00 1.065e+03]\n [1.349e+01 1.660e+00 2.240e+00 2.400e+01 8.700e+01 1.880e+00 1.840e+00\n  2.700e-01 1.030e+00 3.740e+00 9.800e-01 2.780e+00 4.720e+02]\n [1.233e+01 9.900e-01 1.950e+00 1.480e+01 1.360e+02 1.900e+00 1.850e+00\n  3.500e-01 2.760e+00 3.400e+00 1.060e+00 2.310e+00 7.500e+02]\n [1.307e+01 1.500e+00 2.100e+00 1.550e+01 9.800e+01 2.400e+00 2.640e+00\n  2.800e-01 1.370e+00 3.700e+00 1.180e+00 2.690e+00 1.020e+03]]\nthe first 10 of the targets is [0 0 0 1 2 0 0 1 1 0]\n"
    }
   ],
   "source": [
    "# print the first 20 elements\n",
    "index = 10\n",
    "print(\"the first {} of the data is {}\".format(index, X[:index]))\n",
    "print(\"the first {} of the targets is {}\".format(index, y[:index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "first 20 targets are [0 0 0 1 2 0 0 1 1 0 1 0 1 1 0 0 1 0 2 2]\n"
    }
   ],
   "source": [
    "index = 20\n",
    "print(\"first {} targets are {}\".format(index, y[:index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "encoded of shape (178, 1) is now [[0]\n [0]\n [0]\n [1]\n [2]\n [0]\n [0]\n [1]\n [1]\n [0]\n [1]\n [0]\n [1]\n [1]\n [0]\n [0]\n [1]\n [0]\n [2]\n [2]]\nfirst 20 targets are [[1. 0. 0.]\n [1. 0. 0.]\n [1. 0. 0.]\n [0. 1. 0.]\n [0. 0. 1.]\n [1. 0. 0.]\n [1. 0. 0.]\n [0. 1. 0.]\n [0. 1. 0.]\n [1. 0. 0.]\n [0. 1. 0.]\n [1. 0. 0.]\n [0. 1. 0.]\n [0. 1. 0.]\n [1. 0. 0.]\n [1. 0. 0.]\n [0. 1. 0.]\n [1. 0. 0.]\n [0. 0. 1.]\n [0. 0. 1.]]\n"
    }
   ],
   "source": [
    "# one hot the target\n",
    "# binary encode\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "y_onehot = y.reshape(len(y), 1)\n",
    "\n",
    "index = 20\n",
    "print(\"encoded of shape {} is now {}\".format(y_onehot.shape, y_onehot[:index]))\n",
    "\n",
    "y_onehot = onehot_encoder.fit_transform(y_onehot)\n",
    "print(\"first {} targets are {}\".format(index, y_onehot[:index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "the train max index is 178\nthe test split index is 142\nthe validate split index is 113\nthe train dataset if of type <class 'numpy.ndarray'> and shape (113, 13)\nthe test dataset if of type <class 'numpy.ndarray'> and shape (36, 13)\nthe validate dataset if of type <class 'numpy.ndarray'> and shape (29, 13)\n"
    }
   ],
   "source": [
    "# get the train/test data\n",
    "X_train, X_test, X_validate = get_train_test_validate(X, 0.8, 0.8)\n",
    "\n",
    "print(\"the train dataset if of type {} and shape {}\".format(type(X_train), X_train.shape))\n",
    "print(\"the test dataset if of type {} and shape {}\".format(type(X_test), X_test.shape))\n",
    "print(\"the validate dataset if of type {} and shape {}\".format(type(X_validate), X_validate.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "the train max index is 178\nthe test split index is 142\nthe validate split index is 113\nthe train labels if of type <class 'numpy.ndarray'> and shape (113, 3)\nthe test labels if of type <class 'numpy.ndarray'> and shape (36, 3)\nthe validate labels if of type <class 'numpy.ndarray'> and shape (29, 3)\n"
    }
   ],
   "source": [
    "# split the labels into train/test/validate labels\n",
    "y_train, y_test, y_validate = get_train_test_validate(y_onehot, 0.8, 0.8)\n",
    "\n",
    "print(\"the train labels if of type {} and shape {}\".format(type(y_train), y_train.shape))\n",
    "print(\"the test labels if of type {} and shape {}\".format(type(y_test), y_test.shape))\n",
    "print(\"the validate labels if of type {} and shape {}\".format(type(y_validate), y_validate.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense (Dense)                (None, 100)               1400      \n_________________________________________________________________\ndense_1 (Dense)              (None, 30)                3030      \n_________________________________________________________________\ndense_2 (Dense)              (None, 3)                 93        \n=================================================================\nTotal params: 4,523\nTrainable params: 4,523\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "# build the model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100, activation= 'relu', input_shape=(13,)),\n",
    "    # tf.keras.layers.AveragePooling1D(),\n",
    "    tf.keras.layers.Dense(30, activation='relu'),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# will only work if lables are one hot matrix?\n",
    "# from keras.utils import to_categorical\n",
    "# y_binary = to_categorical(y_int)\n",
    "# model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# option from the TF classification example\n",
    "# model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), optimizer='adam', metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train on 113 samples, validate on 29 samples\nEpoch 1/20\n113/113 [==============================] - 0s 3ms/sample - loss: 44.0444 - accuracy: 0.3982 - val_loss: 10.0725 - val_accuracy: 0.5172\nEpoch 2/20\n113/113 [==============================] - 0s 150us/sample - loss: 5.4676 - accuracy: 0.3717 - val_loss: 4.4154 - val_accuracy: 0.3448\nEpoch 3/20\n113/113 [==============================] - 0s 157us/sample - loss: 1.6808 - accuracy: 0.6726 - val_loss: 0.5128 - val_accuracy: 0.7241\nEpoch 4/20\n113/113 [==============================] - 0s 163us/sample - loss: 1.0256 - accuracy: 0.7080 - val_loss: 0.4541 - val_accuracy: 0.8621\nEpoch 5/20\n113/113 [==============================] - 0s 162us/sample - loss: 0.7568 - accuracy: 0.6814 - val_loss: 0.4714 - val_accuracy: 0.7586\nEpoch 6/20\n113/113 [==============================] - 0s 163us/sample - loss: 0.6832 - accuracy: 0.6637 - val_loss: 0.8240 - val_accuracy: 0.7586\nEpoch 7/20\n113/113 [==============================] - 0s 169us/sample - loss: 0.5960 - accuracy: 0.7522 - val_loss: 0.3935 - val_accuracy: 0.7931\nEpoch 8/20\n113/113 [==============================] - 0s 171us/sample - loss: 0.5606 - accuracy: 0.8053 - val_loss: 0.2986 - val_accuracy: 0.8966\nEpoch 9/20\n113/113 [==============================] - 0s 167us/sample - loss: 0.4965 - accuracy: 0.7434 - val_loss: 0.2532 - val_accuracy: 0.9310\nEpoch 10/20\n113/113 [==============================] - 0s 164us/sample - loss: 0.6875 - accuracy: 0.7611 - val_loss: 0.4006 - val_accuracy: 0.7586\nEpoch 11/20\n113/113 [==============================] - 0s 166us/sample - loss: 0.3942 - accuracy: 0.8319 - val_loss: 0.6002 - val_accuracy: 0.7931\nEpoch 12/20\n113/113 [==============================] - 0s 158us/sample - loss: 0.5265 - accuracy: 0.7965 - val_loss: 0.6534 - val_accuracy: 0.7931\nEpoch 13/20\n113/113 [==============================] - 0s 152us/sample - loss: 0.7310 - accuracy: 0.7257 - val_loss: 0.6279 - val_accuracy: 0.7586\nEpoch 14/20\n113/113 [==============================] - 0s 149us/sample - loss: 0.5812 - accuracy: 0.7257 - val_loss: 0.4650 - val_accuracy: 0.7586\nEpoch 15/20\n113/113 [==============================] - 0s 166us/sample - loss: 0.5567 - accuracy: 0.7699 - val_loss: 0.4248 - val_accuracy: 0.7931\nEpoch 16/20\n113/113 [==============================] - 0s 154us/sample - loss: 0.6962 - accuracy: 0.7168 - val_loss: 0.1758 - val_accuracy: 0.9655\nEpoch 17/20\n113/113 [==============================] - 0s 165us/sample - loss: 0.6380 - accuracy: 0.7788 - val_loss: 0.4553 - val_accuracy: 0.7586\nEpoch 18/20\n113/113 [==============================] - 0s 173us/sample - loss: 1.5033 - accuracy: 0.6195 - val_loss: 0.6116 - val_accuracy: 0.7586\nEpoch 19/20\n113/113 [==============================] - 0s 153us/sample - loss: 0.8705 - accuracy: 0.7168 - val_loss: 0.1794 - val_accuracy: 0.9310\nEpoch 20/20\n113/113 [==============================] - 0s 149us/sample - loss: 0.4912 - accuracy: 0.7965 - val_loss: 0.6016 - val_accuracy: 0.8276\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7ff2c9659090>"
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "# fit the model\n",
    "number_epochs=20\n",
    "\n",
    "model.fit(X_train, y_train, epochs=number_epochs, batch_size=10, validation_data=(X_validate, y_validate), verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "the prediction of type <class 'numpy.ndarray'> was [[2.12237135e-01 5.36971763e-02 7.34065711e-01]\n [9.98978138e-01 3.12618283e-07 1.02155155e-03]\n [2.21382664e-03 5.92592597e-01 4.05193567e-01]\n [2.06244318e-03 5.65310299e-01 4.32627350e-01]\n [9.95716631e-01 6.75372632e-07 4.28261748e-03]\n [9.99677181e-01 1.33400064e-08 3.22782813e-04]\n [1.63656533e-01 1.15219034e-01 7.21124411e-01]\n [1.58569927e-03 6.68090954e-03 9.91733432e-01]\n [1.39944544e-02 7.07490683e-01 2.78514892e-01]]\nthe targets are [[1. 0. 0.]\n [1. 0. 0.]\n [0. 1. 0.]\n [0. 1. 0.]\n [1. 0. 0.]\n [1. 0. 0.]\n [0. 1. 0.]\n [0. 0. 1.]\n [0. 1. 0.]]\n"
    }
   ],
   "source": [
    "# predict\n",
    "prediction = model.predict(X_test[1:10])\n",
    "\n",
    "print(\"the prediction of type {} was {}\".format(type(prediction), prediction))\n",
    "print(\"the targets are {}\".format(y_test[1:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "the prediction of type <class 'numpy.ndarray'> was [[0.212 0.054 0.734]\n [0.999 0.000 0.001]\n [0.002 0.593 0.405]\n [0.002 0.565 0.433]\n [0.996 0.000 0.004]\n [1.000 0.000 0.000]\n [0.164 0.115 0.721]\n [0.002 0.007 0.992]\n [0.014 0.707 0.279]]\nthe targets are [[1.000 0.000 0.000]\n [1.000 0.000 0.000]\n [0.000 1.000 0.000]\n [0.000 1.000 0.000]\n [1.000 0.000 0.000]\n [1.000 0.000 0.000]\n [0.000 1.000 0.000]\n [0.000 0.000 1.000]\n [0.000 1.000 0.000]]\n"
    }
   ],
   "source": [
    "# format thwe results\n",
    "float_formatter = \"{:.3f}\".format\n",
    "np.set_printoptions(formatter={'float_kind':float_formatter})\n",
    "\n",
    "print(\"the prediction of type {} was {}\".format(type(prediction), prediction))\n",
    "print(\"the targets are {}\".format(y_test[1:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "the test labels were [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n"
    }
   ],
   "source": [
    "# validate the prediction\n",
    "print(\"the test labels were {}\".format(y_test[1:20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37664bittf237venv9b274482c7ba4966ad2cf02baa9bb24c",
   "display_name": "Python 3.7.6 64-bit ('tf2_37': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}