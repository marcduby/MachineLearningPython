{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37664bittf237venv9b274482c7ba4966ad2cf02baa9bb24c",
   "display_name": "Python 3.7.6 64-bit ('tf2_37': venv)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Version:  2.1.0\nEager mode:  True\nGPU is NOT AVAILABLE\n"
    }
   ],
   "source": [
    "# imports\n",
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "import numpy as np \n",
    "\n",
    "\n",
    "# print environment\n",
    "print(\"Version: \", tf.__version__)\n",
    "print(\"Eager mode: \", tf.executing_eagerly())\n",
    "# print(\"Hub version: \", hub.__version__)\n",
    "print(\"GPU is\", \"available\" if tf.config.experimental.list_physical_devices(\"GPU\") else \"NOT AVAILABLE\")\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "The imdb data is of type <class 'module'>\n"
    }
   ],
   "source": [
    "# get the imdb data\n",
    "imdb_data = keras.datasets.imdb\n",
    "\n",
    "# print\n",
    "print(\"The imdb data is of type {}\".format(type(imdb_data)))\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the train data\n",
    "(train_data, train_label), (test_data, test_label) = imdb_data.load_data(num_words= 10000)\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "the train_data is shape (25000,) and train_label is of shape (25000,)\nthe first row of the training data [1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\nthe first row of the training data is of length 218\nthe first row of the training label 1\n"
    }
   ],
   "source": [
    "# print\n",
    "print(\"the train_data is shape {} and train_label is of shape {}\".format(train_data.shape, train_label.shape))\n",
    "\n",
    "# print\n",
    "print(\"the first row of the training data {}\".format(train_data[0]))\n",
    "print(\"the first row of the training data is of length {}\".format(len(train_data[0])))\n",
    "print(\"the first row of the training label {}\".format(train_label[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "the word in is of shape 88584\n"
    }
   ],
   "source": [
    "# get the word index\n",
    "word_index = imdb_data.get_word_index()\n",
    "\n",
    "# print\n",
    "print(\"the word in is of shape {}\".format(len(word_index)))\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "the word in is of shape 88585\n"
    }
   ],
   "source": [
    "# add in the unknown word\n",
    "word_index = {key: (value+1) for key, value in word_index.items()}\n",
    "\n",
    "# add in space\n",
    "word_index['<pad>'] = 0\n",
    "\n",
    "# print\n",
    "print(\"the word in is of shape {}\".format(len(word_index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "the word at position 0 is: <pad>\nthe word at position 1 is: ?\nthe word at position 2 is: ?\nthe word at position 3 is: ?\nthe word at position 4 is: the\nthe word at position 5 is: and\nthe word at position 6 is: a\nthe word at position 7 is: of\nthe word at position 8 is: to\nthe word at position 9 is: is\n"
    }
   ],
   "source": [
    "# reverse the word index\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "\n",
    "# print\n",
    "for i in range(0, 10):\n",
    "    print(\"the word at position {} is: {}\".format(i, reverse_word_index.get(i, \"?\")))\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "? the ? ? at storytelling the traditional sort many years after the event i can still see in my ? eye an elderly lady my friend's mother retelling the battle of ? she makes the characters come alive her passion is that of an eye witness one to the events on the ? heath a mile or so from where she lives br br of course it happened many years before she was born but you wouldn't guess from the way she tells it the same story is told in bars the length and ? of scotland as i discussed it with a friend one night in ? a local cut in to give his version the discussion continued to closing time br br stories passed down like this become part of our being who doesn't remember the stories our parents told us when we were children they become our invisible world and as we grow older they maybe still serve as inspiration or as an emotional ? fact and fiction blend with ? role models warning stories ? magic and mystery br br my name is ? like my grandfather and his grandfather before him our protagonist introduces himself to us and also introduces the story that stretches back through generations it produces stories within stories stories that evoke the ? wonder of scotland its rugged mountains ? in ? the stuff of legend yet ? is ? in reality this is what gives it its special charm it has a rough beauty and authenticity ? with some of the finest ? singing you will ever hear br br ? ? visits his grandfather in hospital shortly before his death he burns with frustration part of him ? to be in the twenty first century to hang out in ? but he is raised on the western ? among a ? speaking community br br yet there is a deeper conflict within him he ? to know the truth the truth behind his ? ancient stories where does fiction end and he wants to know the truth behind the death of his parents br br he is pulled to make a last ? journey to the ? of one of ? most ? mountains can the truth be told or is it all in stories br br in this story about stories we ? bloody battles ? lovers the ? of old and the sometimes more ? ? of accepted truth in doing so we each connect with ? as he lives the story of his own life br br ? the ? ? is probably the most honest ? and genuinely beautiful film of scotland ever made like ? i got slightly annoyed with the ? of hanging stories on more stories but also like ? i ? this once i saw the ? picture ' forget the box office ? of braveheart and its like you might even ? the ? famous ? of the wicker man to see a film that is true to scotland this one is probably unique if you maybe ? on it deeply enough you might even re ? the power of storytelling and the age old question of whether there are some truths that cannot be told but only experienced\nthe label for this review is 1\n"
    }
   ],
   "source": [
    "# method to decode text\n",
    "def decode_text(text):\n",
    "    return \" \".join([reverse_word_index.get(i, \"?\") for i in text])\n",
    "\n",
    "# print a review\n",
    "index = 3\n",
    "print(decode_text(train_data[index]))\n",
    "print(\"the label for this review is {}\".format(train_label[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "? this has to be one of the worst films of the 1990s when my friends i were watching this film being the target audience it was aimed at we just sat watched the first half an hour with our jaws touching the floor at how bad it really was the rest of the time everyone else in the theatre just started talking to each other leaving or generally crying into their popcorn that they actually paid money they had ? working to watch this feeble excuse for a film it must have looked like a great idea on paper but on film it looks like no one in the film has a clue what is going on crap acting crap costumes i can't get across how ? this is to watch save yourself an hour a bit of your life <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\nthe label for this review is 0\n"
    }
   ],
   "source": [
    "# preprocess the text\n",
    "train_data = keras.preprocessing.sequence.pad_sequences(train_data, value= word_index[\"<pad>\"], padding= \"post\", maxlen= 300)\n",
    "test_data = keras.preprocessing.sequence.pad_sequences(test_data, value= word_index[\"<pad>\"], padding= \"post\", maxlen = 300)\n",
    "\n",
    "# print a review\n",
    "index = 2\n",
    "print(decode_text(train_data[index]))\n",
    "print(\"the label for this review is {}\".format(train_label[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential_3\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_3 (Embedding)      (None, None, 16)          160000    \n_________________________________________________________________\nglobal_average_pooling1d_3 ( (None, 16)                0         \n_________________________________________________________________\ndense_6 (Dense)              (None, 16)                272       \n_________________________________________________________________\ndense_7 (Dense)              (None, 1)                 17        \n=================================================================\nTotal params: 160,289\nTrainable params: 160,289\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "# build the model\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(10000, 16))\n",
    "model.add(keras.layers.GlobalAveragePooling1D())\n",
    "model.add(keras.layers.Dense(16, activation= \"relu\"))\n",
    "model.add(keras.layers.Dense(1, activation= \"sigmoid\"))\n",
    "\n",
    "# summarize the model\n",
    "model.summary()\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer = \"adam\", loss = \"binary_crossentropy\", metrics = [\"accuracy\"])\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "the train is of size 21000 and the validation is of size 4000\n"
    }
   ],
   "source": [
    "# split out the validation data\n",
    "split_index = 4000\n",
    "X_train = train_data[split_index:]\n",
    "X_validation = train_data[:split_index]\n",
    "y_train = train_label[split_index:]\n",
    "y_validation = train_label[:split_index]\n",
    "\n",
    "# print\n",
    "print(\"the train is of size {} and the validation is of size {}\".format(len(X_train), len(X_validation)))\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train on 21000 samples, validate on 4000 samples\nEpoch 1/40\n21000/21000 [==============================] - 1s 34us/sample - loss: 0.6917 - accuracy: 0.5462 - val_loss: 0.6888 - val_accuracy: 0.6875\nEpoch 2/40\n21000/21000 [==============================] - 0s 15us/sample - loss: 0.6837 - accuracy: 0.7224 - val_loss: 0.6773 - val_accuracy: 0.7505\nEpoch 3/40\n21000/21000 [==============================] - 0s 16us/sample - loss: 0.6653 - accuracy: 0.7563 - val_loss: 0.6528 - val_accuracy: 0.7582\nEpoch 4/40\n21000/21000 [==============================] - 0s 15us/sample - loss: 0.6323 - accuracy: 0.7740 - val_loss: 0.6142 - val_accuracy: 0.7805\nEpoch 5/40\n21000/21000 [==============================] - 0s 15us/sample - loss: 0.5852 - accuracy: 0.8048 - val_loss: 0.5653 - val_accuracy: 0.8100\nEpoch 6/40\n21000/21000 [==============================] - 0s 16us/sample - loss: 0.5303 - accuracy: 0.8281 - val_loss: 0.5129 - val_accuracy: 0.8253\nEpoch 7/40\n21000/21000 [==============================] - 0s 15us/sample - loss: 0.4746 - accuracy: 0.8490 - val_loss: 0.4632 - val_accuracy: 0.8422\nEpoch 8/40\n21000/21000 [==============================] - 0s 16us/sample - loss: 0.4249 - accuracy: 0.8632 - val_loss: 0.4250 - val_accuracy: 0.8422\nEpoch 9/40\n21000/21000 [==============================] - 0s 15us/sample - loss: 0.3838 - accuracy: 0.8750 - val_loss: 0.3905 - val_accuracy: 0.8583\nEpoch 10/40\n21000/21000 [==============================] - 0s 16us/sample - loss: 0.3505 - accuracy: 0.8828 - val_loss: 0.3665 - val_accuracy: 0.8660\nEpoch 11/40\n21000/21000 [==============================] - 0s 15us/sample - loss: 0.3239 - accuracy: 0.8893 - val_loss: 0.3476 - val_accuracy: 0.8658\nEpoch 12/40\n21000/21000 [==============================] - 0s 16us/sample - loss: 0.3027 - accuracy: 0.8940 - val_loss: 0.3329 - val_accuracy: 0.8705\nEpoch 13/40\n21000/21000 [==============================] - 0s 16us/sample - loss: 0.2844 - accuracy: 0.8994 - val_loss: 0.3216 - val_accuracy: 0.8775\nEpoch 14/40\n21000/21000 [==============================] - 0s 16us/sample - loss: 0.2677 - accuracy: 0.9070 - val_loss: 0.3120 - val_accuracy: 0.8790\nEpoch 15/40\n21000/21000 [==============================] - 0s 16us/sample - loss: 0.2535 - accuracy: 0.9103 - val_loss: 0.3043 - val_accuracy: 0.8820\nEpoch 16/40\n21000/21000 [==============================] - 0s 16us/sample - loss: 0.2409 - accuracy: 0.9149 - val_loss: 0.2979 - val_accuracy: 0.8835\nEpoch 17/40\n21000/21000 [==============================] - 0s 16us/sample - loss: 0.2297 - accuracy: 0.9193 - val_loss: 0.2928 - val_accuracy: 0.8815\nEpoch 18/40\n21000/21000 [==============================] - 0s 16us/sample - loss: 0.2201 - accuracy: 0.9225 - val_loss: 0.2889 - val_accuracy: 0.8840\nEpoch 19/40\n21000/21000 [==============================] - 0s 16us/sample - loss: 0.2101 - accuracy: 0.9270 - val_loss: 0.2862 - val_accuracy: 0.8863\nEpoch 20/40\n21000/21000 [==============================] - 0s 16us/sample - loss: 0.2014 - accuracy: 0.9296 - val_loss: 0.2844 - val_accuracy: 0.8875\nEpoch 21/40\n21000/21000 [==============================] - 0s 16us/sample - loss: 0.1945 - accuracy: 0.9323 - val_loss: 0.2863 - val_accuracy: 0.8825\nEpoch 22/40\n21000/21000 [==============================] - 0s 16us/sample - loss: 0.1893 - accuracy: 0.9339 - val_loss: 0.2811 - val_accuracy: 0.8860\nEpoch 23/40\n21000/21000 [==============================] - 0s 16us/sample - loss: 0.1820 - accuracy: 0.9367 - val_loss: 0.2808 - val_accuracy: 0.8860\nEpoch 24/40\n21000/21000 [==============================] - 0s 16us/sample - loss: 0.1740 - accuracy: 0.9413 - val_loss: 0.2817 - val_accuracy: 0.8838\nEpoch 25/40\n21000/21000 [==============================] - 0s 17us/sample - loss: 0.1699 - accuracy: 0.9415 - val_loss: 0.2801 - val_accuracy: 0.8882\nEpoch 26/40\n21000/21000 [==============================] - 0s 16us/sample - loss: 0.1629 - accuracy: 0.9455 - val_loss: 0.2806 - val_accuracy: 0.8865\nEpoch 27/40\n21000/21000 [==============================] - 0s 15us/sample - loss: 0.1575 - accuracy: 0.9476 - val_loss: 0.2823 - val_accuracy: 0.8852\nEpoch 28/40\n21000/21000 [==============================] - 0s 17us/sample - loss: 0.1535 - accuracy: 0.9491 - val_loss: 0.2816 - val_accuracy: 0.8888\nEpoch 29/40\n21000/21000 [==============================] - 0s 15us/sample - loss: 0.1476 - accuracy: 0.9524 - val_loss: 0.2845 - val_accuracy: 0.8885\nEpoch 30/40\n21000/21000 [==============================] - 0s 16us/sample - loss: 0.1455 - accuracy: 0.9517 - val_loss: 0.2833 - val_accuracy: 0.8875\nEpoch 31/40\n21000/21000 [==============================] - 0s 16us/sample - loss: 0.1392 - accuracy: 0.9549 - val_loss: 0.2860 - val_accuracy: 0.8855\nEpoch 32/40\n21000/21000 [==============================] - 0s 16us/sample - loss: 0.1347 - accuracy: 0.9570 - val_loss: 0.2888 - val_accuracy: 0.8865\nEpoch 33/40\n21000/21000 [==============================] - 0s 16us/sample - loss: 0.1317 - accuracy: 0.9574 - val_loss: 0.2898 - val_accuracy: 0.8873\nEpoch 34/40\n21000/21000 [==============================] - 0s 17us/sample - loss: 0.1281 - accuracy: 0.9592 - val_loss: 0.2913 - val_accuracy: 0.8863\nEpoch 35/40\n21000/21000 [==============================] - 0s 17us/sample - loss: 0.1240 - accuracy: 0.9610 - val_loss: 0.2954 - val_accuracy: 0.8867\nEpoch 36/40\n21000/21000 [==============================] - 0s 16us/sample - loss: 0.1196 - accuracy: 0.9623 - val_loss: 0.2964 - val_accuracy: 0.8870\nEpoch 37/40\n21000/21000 [==============================] - 0s 16us/sample - loss: 0.1160 - accuracy: 0.9639 - val_loss: 0.2997 - val_accuracy: 0.8865\nEpoch 38/40\n21000/21000 [==============================] - 0s 16us/sample - loss: 0.1141 - accuracy: 0.9643 - val_loss: 0.3013 - val_accuracy: 0.8863\nEpoch 39/40\n21000/21000 [==============================] - 0s 16us/sample - loss: 0.1102 - accuracy: 0.9664 - val_loss: 0.3069 - val_accuracy: 0.8852\nEpoch 40/40\n21000/21000 [==============================] - 0s 17us/sample - loss: 0.1112 - accuracy: 0.9655 - val_loss: 0.3075 - val_accuracy: 0.8850\n25000/25000 [==============================] - 0s 19us/sample - loss: 0.3310 - accuracy: 0.8753\nthe evaluation results are [0.3310071557331085, 0.87528]\n"
    }
   ],
   "source": [
    "# fit the model\n",
    "model_fit = model.fit(X_train, y_train, epochs = 40, batch_size = 512, validation_data = (X_validation, y_validation), verbose = 1)\n",
    "\n",
    "# evaluate the fit\n",
    "result = model.evaluate(test_data, test_label)\n",
    "\n",
    "print(\"the evaluation results are {}\".format(result))\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}