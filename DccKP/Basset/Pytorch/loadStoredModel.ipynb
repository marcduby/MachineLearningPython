{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copied from github below for use in my project at work\n",
    "# https://github.com/kipoi/models/blob/master/Basset/pretrained_model_reloaded_th.py\n",
    "# see paper at\n",
    "# http://kipoi.org/models/Basset/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "got pytorch version of 1.5.1\n"
    }
   ],
   "source": [
    "# imports\n",
    "import torch\n",
    "from torch import nn\n",
    "import twobitreader\n",
    "from twobitreader import TwoBitFile\n",
    "\n",
    "print(\"got pytorch version of {}\".format(torch.__version__))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "have pytorch version 1.5.1\nhave numpy version 1.19.0\n"
    }
   ],
   "source": [
    "# import relative libraries\n",
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "import dcc_basset_lib\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LambdaBase(nn.Sequential):\n",
    "    def __init__(self, fn, *args):\n",
    "        super(LambdaBase, self).__init__(*args)\n",
    "        self.lambda_func = fn\n",
    "\n",
    "    def forward_prepare(self, input):\n",
    "        output = []\n",
    "        for module in self._modules.values():\n",
    "            output.append(module(input))\n",
    "        return output if output else input\n",
    "\n",
    "class Lambda(LambdaBase):\n",
    "    def forward(self, input):\n",
    "        return self.lambda_func(self.forward_prepare(input))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "got model of type <class 'torch.nn.modules.container.Sequential'>\n"
    }
   ],
   "source": [
    "# load the Basset model\n",
    "pretrained_model_reloaded_th = nn.Sequential( # Sequential,\n",
    "        nn.Conv2d(4,300,(19, 1)),\n",
    "        nn.BatchNorm2d(300),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d((3, 1),(3, 1)),\n",
    "        nn.Conv2d(300,200,(11, 1)),\n",
    "        nn.BatchNorm2d(200),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d((4, 1),(4, 1)),\n",
    "        nn.Conv2d(200,200,(7, 1)),\n",
    "        nn.BatchNorm2d(200),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d((4, 1),(4, 1)),\n",
    "        Lambda(lambda x: x.view(x.size(0),-1)), # Reshape,\n",
    "        nn.Sequential(Lambda(lambda x: x.view(1,-1) if 1==len(x.size()) else x ),nn.Linear(2000,1000)), # Linear,\n",
    "        nn.BatchNorm1d(1000,1e-05,0.1,True),#BatchNorm1d,\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.3),\n",
    "        nn.Sequential(Lambda(lambda x: x.view(1,-1) if 1==len(x.size()) else x ),nn.Linear(1000,1000)), # Linear,\n",
    "        nn.BatchNorm1d(1000,1e-05,0.1,True),#BatchNorm1d,\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.3),\n",
    "        nn.Sequential(Lambda(lambda x: x.view(1,-1) if 1==len(x.size()) else x ),nn.Linear(1000,164)), # Linear,\n",
    "        nn.Sigmoid(),\n",
    "    )\n",
    "\n",
    "print(\"got model of type {}\".format(type(pretrained_model_reloaded_th)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Sequential(\n  (0): Conv2d(4, 300, kernel_size=(19, 1), stride=(1, 1))\n  (1): BatchNorm2d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (2): ReLU()\n  (3): MaxPool2d(kernel_size=(3, 1), stride=(3, 1), padding=0, dilation=1, ceil_mode=False)\n  (4): Conv2d(300, 200, kernel_size=(11, 1), stride=(1, 1))\n  (5): BatchNorm2d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (6): ReLU()\n  (7): MaxPool2d(kernel_size=(4, 1), stride=(4, 1), padding=0, dilation=1, ceil_mode=False)\n  (8): Conv2d(200, 200, kernel_size=(7, 1), stride=(1, 1))\n  (9): BatchNorm2d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (10): ReLU()\n  (11): MaxPool2d(kernel_size=(4, 1), stride=(4, 1), padding=0, dilation=1, ceil_mode=False)\n  (12): Lambda()\n  (13): Sequential(\n    (0): Lambda()\n    (1): Linear(in_features=2000, out_features=1000, bias=True)\n  )\n  (14): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (15): ReLU()\n  (16): Dropout(p=0.3, inplace=False)\n  (17): Sequential(\n    (0): Lambda()\n    (1): Linear(in_features=1000, out_features=1000, bias=True)\n  )\n  (18): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (19): ReLU()\n  (20): Dropout(p=0.3, inplace=False)\n  (21): Sequential(\n    (0): Lambda()\n    (1): Linear(in_features=1000, out_features=164, bias=True)\n  )\n  (22): Sigmoid()\n)\n"
    }
   ],
   "source": [
    "# print out the model\n",
    "print(pretrained_model_reloaded_th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "# load the weights\n",
    "# sd = torch.load('/home/javaprog/Data/Broad/Basset/Model/predictions.h5')\n",
    "sd = torch.load('/home/javaprog/Data/Broad/Basset/Model/pretrained_model_reloaded_th.pth')\n",
    "pretrained_model_reloaded_th.load_state_dict(sd)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize the model - LARGE\n",
    "model_weights = pretrained_model_reloaded_th.state_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Sequential(\n  (0): Conv2d(4, 300, kernel_size=(19, 1), stride=(1, 1))\n  (1): BatchNorm2d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (2): ReLU()\n  (3): MaxPool2d(kernel_size=(3, 1), stride=(3, 1), padding=0, dilation=1, ceil_mode=False)\n  (4): Conv2d(300, 200, kernel_size=(11, 1), stride=(1, 1))\n  (5): BatchNorm2d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (6): ReLU()\n  (7): MaxPool2d(kernel_size=(4, 1), stride=(4, 1), padding=0, dilation=1, ceil_mode=False)\n  (8): Conv2d(200, 200, kernel_size=(7, 1), stride=(1, 1))\n  (9): BatchNorm2d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (10): ReLU()\n  (11): MaxPool2d(kernel_size=(4, 1), stride=(4, 1), padding=0, dilation=1, ceil_mode=False)\n  (12): Lambda()\n  (13): Sequential(\n    (0): Lambda()\n    (1): Linear(in_features=2000, out_features=1000, bias=True)\n  )\n  (14): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (15): ReLU()\n  (16): Dropout(p=0.3, inplace=False)\n  (17): Sequential(\n    (0): Lambda()\n    (1): Linear(in_features=1000, out_features=1000, bias=True)\n  )\n  (18): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (19): ReLU()\n  (20): Dropout(p=0.3, inplace=False)\n  (21): Sequential(\n    (0): Lambda()\n    (1): Linear(in_features=1000, out_features=164, bias=True)\n  )\n  (22): Sigmoid()\n)\n"
    }
   ],
   "source": [
    "# make the model eval\n",
    "pretrained_model_reloaded_th.eval()\n",
    "\n",
    "# better summary\n",
    "print(pretrained_model_reloaded_th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "two bit file of type <class 'twobitreader.TwoBitFile'>\ngot ref sequence one hot of type <class 'str'> and shape 600\ngot alt sequence one hot of type <class 'str'> and shape 600\n"
    }
   ],
   "source": [
    "# load the chromosome data\n",
    "# get the genome file\n",
    "hg19 = TwoBitFile('../../../../../../Data/Broad/Basset/TwoBitReader/hg19.2bit')\n",
    "\n",
    "print(\"two bit file of type {}\".format(type(hg19)))\n",
    "\n",
    "# get the chrom\n",
    "chromosome = hg19['chr11']\n",
    "position = 95311422\n",
    "\n",
    "# load the data\n",
    "ref_sequence, alt_sequence = dcc_basset_lib.get_ref_alt_sequences(position, 300, chromosome, 'C')\n",
    "\n",
    "print(\"got ref sequence one hot of type {} and shape {}\".format(type(ref_sequence), len(ref_sequence)))\n",
    "print(\"got alt sequence one hot of type {} and shape {}\".format(type(alt_sequence), len(alt_sequence)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "got sequence one hot of type <class 'numpy.ndarray'> and shape (2, 600, 4)\n"
    }
   ],
   "source": [
    "# build list and transform into input\n",
    "sequence_list = []\n",
    "sequence_list.append(ref_sequence)\n",
    "sequence_list.append(alt_sequence)\n",
    "\n",
    "# get the np array of right shape\n",
    "sequence_one_hot = dcc_basset_lib.get_one_hot_sequence_array(sequence_list)\n",
    "print(\"got sequence one hot of type {} and shape {}\".format(type(sequence_one_hot), sequence_one_hot.shape))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "got pytorch tensor with type <class 'torch.Tensor'> and shape torch.Size([2, 600, 4]) and data type \ntorch.float64\n"
    }
   ],
   "source": [
    "# create a pytorch tensor\n",
    "tensor = torch.from_numpy(sequence_one_hot)\n",
    "\n",
    "print(\"got pytorch tensor with type {} and shape {} and data type \\n{}\".format(type(tensor), tensor.shape, tensor.dtype))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "got pytorch tensor with type <class 'torch.Tensor'> and shape torch.Size([2, 4, 600, 1]) and data type \ntorch.float32\n"
    }
   ],
   "source": [
    "# add a dimension to the tensor and convert to float 32\n",
    "tensor_input = torch.unsqueeze(tensor, 3)\n",
    "tensor_input = torch.transpose(tensor_input, 1, 2)\n",
    "tensor_input = tensor_input.to(torch.float)\n",
    "\n",
    "print(\"got pytorch tensor with type {} and shape {} and data type \\n{}\".format(type(tensor_input), tensor_input.shape, tensor_input.dtype))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "got predictions of type <class 'torch.Tensor'> and shape torch.Size([2, 164]) and result \ntensor([[1.0749e-02, 1.0213e-03, 1.4848e-02, 6.5434e-03, 8.6458e-02, 3.0645e-02,\n         4.6448e-03, 5.1843e-03, 4.9607e-03, 7.4255e-03, 9.2591e-03, 7.7353e-03,\n         2.2206e-02, 3.3359e-03, 3.6842e-03, 2.9438e-02, 4.2232e-03, 9.1712e-04,\n         1.6221e-03, 1.0524e-02, 3.6748e-03, 1.8557e-03, 1.6109e-03, 1.3017e-03,\n         3.6147e-03, 1.0297e-02, 6.1578e-02, 6.6933e-02, 1.0849e-02, 7.4299e-02,\n         6.2833e-03, 1.7966e-02, 3.4399e-02, 6.2949e-03, 2.3675e-03, 1.8804e-03,\n         9.4161e-03, 2.7993e-02, 2.4177e-03, 8.7791e-03, 8.7258e-04, 6.5026e-04,\n         1.0449e-03, 4.0967e-04, 5.7718e-04, 7.3653e-04, 1.3984e-02, 6.1543e-04,\n         4.3805e-04, 1.3010e-02, 8.3348e-03, 1.8281e-02, 9.5618e-03, 2.8722e-02,\n         2.6964e-02, 1.4387e-02, 6.9775e-04, 2.8968e-03, 1.2265e-03, 7.0210e-03,\n         2.7426e-03, 6.4689e-04, 4.3560e-03, 1.0491e-03, 6.2473e-04, 2.2319e-03,\n         3.2119e-03, 1.1354e-02, 1.2104e-03, 3.4432e-03, 5.9469e-04, 3.3928e-03,\n         3.7155e-02, 1.2089e-03, 1.8463e-03, 4.0443e-03, 5.0282e-03, 2.2996e-03,\n         2.6947e-03, 1.8705e-03, 5.1552e-03, 3.4999e-03, 1.6236e-03, 2.9921e-03,\n         1.1472e-03, 1.0593e-03, 7.3469e-04, 1.6141e-03, 1.6071e-03, 5.5159e-03,\n         4.2331e-03, 2.5938e-03, 1.8131e-02, 2.1088e-02, 1.1350e-02, 8.4701e-04,\n         3.2079e-03, 1.2688e-03, 9.5659e-04, 6.0898e-03, 9.7379e-03, 8.7160e-03,\n         3.8195e-03, 1.0798e-02, 2.4667e-03, 5.4795e-03, 1.1249e-03, 8.9578e-03,\n         4.7724e-02, 1.9501e-03, 2.6532e-02, 1.2210e-02, 3.5450e-02, 6.2203e-03,\n         4.4122e-03, 4.0126e-03, 4.0712e-02, 9.5034e-03, 1.2110e-02, 7.3350e-03,\n         2.9072e-02, 1.7267e-02, 1.1328e-02, 1.3954e-02, 5.5965e-02, 1.7509e-03,\n         9.5685e-03, 5.0565e-03, 7.1103e-03, 5.2643e-03, 6.4775e-03, 1.5771e-02,\n         6.3385e-03, 4.6265e-03, 1.1277e-02, 1.2858e-02, 1.9697e-02, 4.9991e-03,\n         8.0047e-03, 1.6899e-02, 1.0304e-02, 3.1609e-03, 2.9354e-03, 3.9112e-02,\n         1.3295e-02, 8.6411e-03, 8.2268e-03, 6.4672e-03, 9.3496e-03, 6.8365e-03,\n         3.1227e-03, 3.2497e-03, 1.6470e-02, 2.5303e-03, 4.3481e-03, 5.4795e-03,\n         4.9274e-03, 1.7367e-03, 1.9647e-03, 4.0503e-03, 2.3167e-03, 2.3633e-02,\n         1.0635e-02, 9.8918e-04],\n        [3.5667e-01, 2.2641e-01, 1.3099e-01, 1.5814e-01, 2.8597e-01, 3.1178e-01,\n         3.3317e-01, 2.3158e-01, 2.0979e-01, 2.6381e-01, 2.8659e-01, 2.7067e-01,\n         3.2659e-01, 5.7054e-01, 3.6756e-01, 1.5671e-01, 3.7154e-01, 1.8765e-01,\n         3.6460e-01, 3.9095e-01, 4.6317e-01, 3.8480e-01, 2.8521e-01, 2.9176e-01,\n         3.0726e-01, 4.8602e-01, 2.6439e-01, 2.7266e-01, 2.4169e-01, 2.4275e-01,\n         2.9902e-01, 1.9572e-01, 2.9025e-01, 2.4487e-01, 3.2611e-01, 2.6696e-01,\n         3.3626e-01, 2.7354e-01, 3.0678e-01, 2.7878e-01, 2.0029e-01, 1.9739e-01,\n         3.1765e-01, 2.0176e-01, 2.4328e-01, 2.7840e-01, 5.6629e-01, 1.5547e-01,\n         4.7217e-02, 2.8489e-01, 5.4237e-01, 3.6118e-01, 1.2497e-01, 3.7876e-01,\n         5.1615e-01, 6.9201e-01, 3.0602e-01, 2.8940e-01, 2.8668e-01, 2.3777e-01,\n         4.1001e-01, 3.1554e-01, 4.3118e-01, 3.7596e-01, 3.4249e-01, 4.8498e-01,\n         6.5198e-01, 4.9911e-01, 4.3817e-01, 4.8326e-01, 1.7586e-01, 3.9482e-01,\n         3.1670e-01, 3.4660e-01, 2.9253e-01, 4.2617e-01, 5.2442e-01, 4.1056e-01,\n         4.1678e-01, 4.3075e-01, 4.6532e-01, 4.6783e-01, 3.6287e-01, 2.7427e-01,\n         4.3164e-01, 2.5145e-01, 2.8059e-01, 3.1131e-01, 2.7833e-01, 4.4521e-01,\n         2.6218e-01, 2.3152e-01, 6.0062e-01, 2.7240e-01, 5.0185e-01, 1.3769e-01,\n         2.9743e-01, 1.9856e-01, 1.7541e-01, 6.2244e-01, 6.1050e-01, 2.6666e-01,\n         3.6917e-01, 4.1887e-01, 2.2064e-01, 3.1276e-01, 7.3483e-02, 1.7088e-01,\n         5.3705e-01, 3.4171e-01, 3.6972e-01, 5.4564e-01, 3.9347e-01, 6.0704e-01,\n         4.3407e-01, 4.5721e-01, 4.1331e-01, 2.5882e-01, 3.7094e-01, 3.5163e-01,\n         3.9081e-01, 4.1985e-01, 6.3916e-01, 3.7515e-01, 2.8874e-01, 2.8853e-01,\n         6.6305e-01, 7.6076e-01, 7.5412e-01, 7.2586e-01, 2.9947e-01, 7.0083e-01,\n         2.4752e-01, 2.8928e-01, 3.2658e-01, 3.3859e-01, 2.2262e-01, 4.5735e-01,\n         4.6592e-01, 3.1032e-01, 2.8270e-01, 4.1263e-01, 3.7462e-01, 3.7214e-01,\n         3.7795e-01, 3.6844e-01, 3.4070e-01, 2.6435e-01, 2.0260e-01, 1.5950e-01,\n         2.1740e-01, 1.9083e-01, 3.5426e-01, 3.1002e-01, 2.8707e-01, 2.0783e-01,\n         3.6599e-01, 3.0035e-01, 2.1611e-01, 2.8212e-01, 1.4322e-01, 3.8750e-01,\n         4.3963e-01, 2.1643e-01]], grad_fn=<SigmoidBackward>)\n"
    }
   ],
   "source": [
    "# run the model predictions\n",
    "pretrained_model_reloaded_th.eval()\n",
    "predictions = pretrained_model_reloaded_th(tensor_input)\n",
    "\n",
    "print(\"got predictions of type {} and shape {} and result \\n{}\".format(type(predictions), predictions.shape, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1594267031575",
   "display_name": "Python 3.6.9 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}