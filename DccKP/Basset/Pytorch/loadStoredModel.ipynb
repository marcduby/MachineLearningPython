{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copied from github below for use in my project at work\n",
    "# https://github.com/kipoi/models/blob/master/Basset/pretrained_model_reloaded_th.py\n",
    "# see paper at\n",
    "# http://kipoi.org/models/Basset/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "got pytorch version of 1.5.1\n"
    }
   ],
   "source": [
    "# imports\n",
    "import torch\n",
    "from torch import nn\n",
    "import twobitreader\n",
    "from twobitreader import TwoBitFile\n",
    "\n",
    "print(\"got pytorch version of {}\".format(torch.__version__))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "have pytorch version 1.5.1\nhave numpy version 1.19.0\n"
    }
   ],
   "source": [
    "# import relative libraries\n",
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "import dcc_basset_lib\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LambdaBase(nn.Sequential):\n",
    "    def __init__(self, fn, *args):\n",
    "        super(LambdaBase, self).__init__(*args)\n",
    "        self.lambda_func = fn\n",
    "\n",
    "    def forward_prepare(self, input):\n",
    "        output = []\n",
    "        for module in self._modules.values():\n",
    "            output.append(module(input))\n",
    "        return output if output else input\n",
    "\n",
    "class Lambda(LambdaBase):\n",
    "    def forward(self, input):\n",
    "        return self.lambda_func(self.forward_prepare(input))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "got model of type <class 'torch.nn.modules.container.Sequential'>\n"
    }
   ],
   "source": [
    "# load the Basset model\n",
    "pretrained_model_reloaded_th = nn.Sequential( # Sequential,\n",
    "        nn.Conv2d(4,300,(19, 1)),\n",
    "        nn.BatchNorm2d(300),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d((3, 1),(3, 1)),\n",
    "        nn.Conv2d(300,200,(11, 1)),\n",
    "        nn.BatchNorm2d(200),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d((4, 1),(4, 1)),\n",
    "        nn.Conv2d(200,200,(7, 1)),\n",
    "        nn.BatchNorm2d(200),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d((4, 1),(4, 1)),\n",
    "        Lambda(lambda x: x.view(x.size(0),-1)), # Reshape,\n",
    "        nn.Sequential(Lambda(lambda x: x.view(1,-1) if 1==len(x.size()) else x ),nn.Linear(2000,1000)), # Linear,\n",
    "        nn.BatchNorm1d(1000,1e-05,0.1,True),#BatchNorm1d,\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.3),\n",
    "        nn.Sequential(Lambda(lambda x: x.view(1,-1) if 1==len(x.size()) else x ),nn.Linear(1000,1000)), # Linear,\n",
    "        nn.BatchNorm1d(1000,1e-05,0.1,True),#BatchNorm1d,\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.3),\n",
    "        nn.Sequential(Lambda(lambda x: x.view(1,-1) if 1==len(x.size()) else x ),nn.Linear(1000,164)), # Linear,\n",
    "        nn.Sigmoid(),\n",
    "    )\n",
    "\n",
    "print(\"got model of type {}\".format(type(pretrained_model_reloaded_th)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Sequential(\n  (0): Conv2d(4, 300, kernel_size=(19, 1), stride=(1, 1))\n  (1): BatchNorm2d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (2): ReLU()\n  (3): MaxPool2d(kernel_size=(3, 1), stride=(3, 1), padding=0, dilation=1, ceil_mode=False)\n  (4): Conv2d(300, 200, kernel_size=(11, 1), stride=(1, 1))\n  (5): BatchNorm2d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (6): ReLU()\n  (7): MaxPool2d(kernel_size=(4, 1), stride=(4, 1), padding=0, dilation=1, ceil_mode=False)\n  (8): Conv2d(200, 200, kernel_size=(7, 1), stride=(1, 1))\n  (9): BatchNorm2d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (10): ReLU()\n  (11): MaxPool2d(kernel_size=(4, 1), stride=(4, 1), padding=0, dilation=1, ceil_mode=False)\n  (12): Lambda()\n  (13): Sequential(\n    (0): Lambda()\n    (1): Linear(in_features=2000, out_features=1000, bias=True)\n  )\n  (14): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (15): ReLU()\n  (16): Dropout(p=0.3, inplace=False)\n  (17): Sequential(\n    (0): Lambda()\n    (1): Linear(in_features=1000, out_features=1000, bias=True)\n  )\n  (18): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (19): ReLU()\n  (20): Dropout(p=0.3, inplace=False)\n  (21): Sequential(\n    (0): Lambda()\n    (1): Linear(in_features=1000, out_features=164, bias=True)\n  )\n  (22): Sigmoid()\n)\n"
    }
   ],
   "source": [
    "# print out the model\n",
    "print(pretrained_model_reloaded_th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "# load the weights\n",
    "# sd = torch.load('/home/javaprog/Data/Broad/Basset/Model/predictions.h5')\n",
    "sd = torch.load('/home/javaprog/Data/Broad/Basset/Model/pretrained_model_reloaded_th.pth')\n",
    "pretrained_model_reloaded_th.load_state_dict(sd)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize the model - LARGE\n",
    "model_weights = pretrained_model_reloaded_th.state_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Sequential(\n  (0): Conv2d(4, 300, kernel_size=(19, 1), stride=(1, 1))\n  (1): BatchNorm2d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (2): ReLU()\n  (3): MaxPool2d(kernel_size=(3, 1), stride=(3, 1), padding=0, dilation=1, ceil_mode=False)\n  (4): Conv2d(300, 200, kernel_size=(11, 1), stride=(1, 1))\n  (5): BatchNorm2d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (6): ReLU()\n  (7): MaxPool2d(kernel_size=(4, 1), stride=(4, 1), padding=0, dilation=1, ceil_mode=False)\n  (8): Conv2d(200, 200, kernel_size=(7, 1), stride=(1, 1))\n  (9): BatchNorm2d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (10): ReLU()\n  (11): MaxPool2d(kernel_size=(4, 1), stride=(4, 1), padding=0, dilation=1, ceil_mode=False)\n  (12): Lambda()\n  (13): Sequential(\n    (0): Lambda()\n    (1): Linear(in_features=2000, out_features=1000, bias=True)\n  )\n  (14): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (15): ReLU()\n  (16): Dropout(p=0.3, inplace=False)\n  (17): Sequential(\n    (0): Lambda()\n    (1): Linear(in_features=1000, out_features=1000, bias=True)\n  )\n  (18): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (19): ReLU()\n  (20): Dropout(p=0.3, inplace=False)\n  (21): Sequential(\n    (0): Lambda()\n    (1): Linear(in_features=1000, out_features=164, bias=True)\n  )\n  (22): Sigmoid()\n)\n"
    }
   ],
   "source": [
    "# make the model eval\n",
    "pretrained_model_reloaded_th.eval()\n",
    "\n",
    "# better summary\n",
    "print(pretrained_model_reloaded_th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "two bit file of type <class 'twobitreader.TwoBitFile'>\ngot ref sequence one hot of type <class 'str'> and shape 300\ngot alt sequence one hot of type <class 'str'> and shape 300\n"
    }
   ],
   "source": [
    "# load the chromosome data\n",
    "# get the genome file\n",
    "hg19 = TwoBitFile('../../../../../../Data/Broad/Basset/TwoBitReader/hg19.2bit')\n",
    "\n",
    "print(\"two bit file of type {}\".format(type(hg19)))\n",
    "\n",
    "# get the chrom\n",
    "chromosome = hg19['chr11']\n",
    "position = 95311422\n",
    "\n",
    "# load the data\n",
    "ref_sequence, alt_sequence = dcc_basset_lib.get_ref_alt_sequences(position, 150, chromosome, 'C')\n",
    "\n",
    "print(\"got ref sequence one hot of type {} and shape {}\".format(type(ref_sequence), len(ref_sequence)))\n",
    "print(\"got alt sequence one hot of type {} and shape {}\".format(type(alt_sequence), len(alt_sequence)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "got sequence one hot of type <class 'numpy.ndarray'> and shape (2, 300, 4)\n"
    }
   ],
   "source": [
    "# build list and transform into input\n",
    "sequence_list = []\n",
    "sequence_list.append(ref_sequence)\n",
    "sequence_list.append(alt_sequence)\n",
    "\n",
    "# get the np array of right shape\n",
    "sequence_one_hot = dcc_basset_lib.get_one_hot_sequence_array(sequence_list)\n",
    "print(\"got sequence one hot of type {} and shape {}\".format(type(sequence_one_hot), sequence_one_hot.shape))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "got pytorch tensor with type <class 'torch.Tensor'> and shape torch.Size([2, 300, 4]) and data \ntensor([[[0., 0., 1., 0.],\n         [0., 0., 0., 1.],\n         [0., 1., 0., 0.],\n         ...,\n         [0., 0., 0., 1.],\n         [0., 0., 1., 0.],\n         [1., 0., 0., 0.]],\n\n        [[0., 0., 1., 0.],\n         [0., 0., 0., 1.],\n         [0., 1., 0., 0.],\n         ...,\n         [0., 0., 0., 1.],\n         [0., 0., 1., 0.],\n         [1., 0., 0., 0.]]], dtype=torch.float64)\n"
    }
   ],
   "source": [
    "# create a pytorch tensor\n",
    "tensor = torch.from_numpy(sequence_one_hot)\n",
    "\n",
    "print(\"got pytorch tensor with type {} and shape {} and data \\n{}\".format(type(tensor), tensor.shape, tensor))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "Expected 4-dimensional input for 4-dimensional weight [300, 4, 19, 1], but got 3-dimensional input of size [2, 600, 4] instead",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-8995b10f7859>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# run the model predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpretrained_model_reloaded_th\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpretrained_model_reloaded_th\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"got predictions of type {} and shape {} and result \\n{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Apps/VirtualEnvs/kipoi_36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Apps/VirtualEnvs/kipoi_36/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Apps/VirtualEnvs/kipoi_36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Apps/VirtualEnvs/kipoi_36/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Apps/VirtualEnvs/kipoi_36/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    348\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    349\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 350\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected 4-dimensional input for 4-dimensional weight [300, 4, 19, 1], but got 3-dimensional input of size [2, 600, 4] instead"
     ]
    }
   ],
   "source": [
    "# run the model predictions\n",
    "pretrained_model_reloaded_th.eval()\n",
    "predictions = pretrained_model_reloaded_th(tensor)\n",
    "\n",
    "print(\"got predictions of type {} and shape {} and result \\n{}\".format(type(predictions), predictions.shape, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1594258123260",
   "display_name": "Python 3.6.9 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}