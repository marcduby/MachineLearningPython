{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, BooleanType, DoubleType, IntegerType\n",
    "from pyspark.sql.functions import col, struct, explode, when, lit, array_max, array, split, regexp_replace\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "the variant input directory is: /Users/mduby/Data/Broad/Magma/Common/part*\nthe phenotype input directory is: /Users/mduby/Data/Broad/Magma/Phenotype/*/part-*\nthe output directory is: /Users/mduby/Data/Broad/Magma/Out/Step2\n"
    }
   ],
   "source": [
    "# variant_srcdir = 's3://dig-analysis-data/out/varianteffect/common/part-*'\n",
    "# outdir = 's3:/dig-analysis-data/out/varianteffect/magma/'\n",
    "\n",
    "# development localhost directories\n",
    "phenotype_srcdir = '/Users/mduby/Data/Broad/Magma/Phenotype/*/part-*'\n",
    "variant_srcdir = '/Users/mduby/Data/Broad/Magma/Common/part*'\n",
    "out_dir = '/Users/mduby/Data/Broad/Magma/Out/Step2'\n",
    "\n",
    "# print\n",
    "print(\"the variant input directory is: {}\".format(variant_srcdir))\n",
    "print(\"the phenotype input directory is: {}\".format(phenotype_srcdir))\n",
    "print(\"the output directory is: {}\".format(out_dir))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "phenotype_schema = StructType(\n",
    "    [\n",
    "        StructField('varId', StringType(), nullable=False),\n",
    "        StructField('chromosome', StringType(), nullable=False),\n",
    "        StructField('position', IntegerType(), nullable=False),\n",
    "        StructField('reference', StringType(), nullable=False),\n",
    "        StructField('alt', StringType(), nullable=False),\n",
    "        StructField('phenotype', StringType(), nullable=False),\n",
    "        StructField('pValue', DoubleType(), nullable=False),\n",
    "        StructField('beta', DoubleType(), nullable=False),\n",
    "        StructField('zScore', DoubleType(), nullable=False),\n",
    "        StructField('stdErr', DoubleType(), nullable=False),\n",
    "        StructField('n', DoubleType(), nullable=False),\n",
    "        StructField('top', BooleanType(), nullable=False),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# this is the schema for the common variant file\n",
    "variant_schema = StructType(\n",
    "    [\n",
    "        StructField('varId', StringType(), nullable=False),\n",
    "        StructField('dbSNP', StringType(), nullable=False),\n",
    "        StructField('consequence', StringType(), nullable=False),\n",
    "        StructField('gene', StringType(), nullable=False),\n",
    "        StructField('transcript', StringType(), nullable=False),\n",
    "        StructField('impact', StringType(), nullable=False),\n",
    "    ]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "got Spark session of type <class 'pyspark.sql.session.SparkSession'>\n"
    }
   ],
   "source": [
    "# %%\n",
    "# open spark session\n",
    "spark = SparkSession.builder.appName('bioindex').getOrCreate()\n",
    "\n",
    "print(\"got Spark session of type {}\".format(type(spark)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "the loaded variant data frame has 67003328 rows\n+---------------+-----------+\n|          varId|      dbSNP|\n+---------------+-----------+\n|1:62185338:AT:A|       null|\n| 1:62190015:G:T|rs147606427|\n| 1:62190786:C:T|       null|\n| 1:62192716:A:G|rs185779444|\n| 1:62197508:T:C|rs114282349|\n+---------------+-----------+\nonly showing top 5 rows\n\n"
    }
   ],
   "source": [
    "# load the variants\n",
    "df_variant_load = spark.read.csv(variant_srcdir, sep='\\t', header=True, schema=variant_schema).select('varId', 'dbSNP')\n",
    "\n",
    "# print\n",
    "print(\"the loaded variant data frame has {} rows\".format(df_variant_load.count()))\n",
    "df_variant_load.show(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "the non null RS id variant dataframe has 59203797 rows\n+--------------+-----------+\n|         varId|      dbSNP|\n+--------------+-----------+\n|1:62190015:G:T|rs147606427|\n|1:62192716:A:G|rs185779444|\n|1:62197508:T:C|rs114282349|\n|1:62204697:C:G|rs554118633|\n|1:62204701:G:T|rs575749077|\n+--------------+-----------+\nonly showing top 5 rows\n\n"
    }
   ],
   "source": [
    "# keep only the rows with non null dbSNP ids\n",
    "df_variant_load = df_variant_load.filter(col(\"dbSNP\").isNotNull())\n",
    "\n",
    "# print\n",
    "print(\"the non null RS id variant dataframe has {} rows\".format(df_variant_load.count()))\n",
    "df_variant_load.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "the loaded phenotype data frame has 60745157 rows\n+------------------+---------+------+--------+\n|             varId|phenotype|pValue|       n|\n+------------------+---------+------+--------+\n|  10:100008663:T:C|      T2D| 0.666|  6104.0|\n|  10:100009881:A:G|      T2D|0.1209|  4347.0|\n|   10:10001222:C:A|      T2D|  0.45|102677.0|\n|  10:100013493:C:T|      T2D|0.9751| 29076.0|\n|10:100028288:G:GCA|      T2D|0.1559| 96318.0|\n+------------------+---------+------+--------+\nonly showing top 5 rows\n\n"
    }
   ],
   "source": [
    "# load the phenotypes\n",
    "df_phenotype_load = spark.read.csv(phenotype_srcdir, sep='\\t', header=True, schema=phenotype_schema).select('varId', 'phenotype', 'pValue', 'n')\n",
    "\n",
    "# print\n",
    "print(\"the loaded phenotype data frame has {} rows\".format(df_phenotype_load.count()))\n",
    "df_phenotype_load.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "the loaded joined data frame has 48149817 rows\n+----------------+-----------+---------+------+--------+\n|           varId|      dbSNP|phenotype|pValue|       n|\n+----------------+-----------+---------+------+--------+\n|10:100005684:C:G|rs145568860|      T2D|  0.49|442817.0|\n|10:100016209:A:G|rs193028079|      T2D|  0.69|110767.0|\n|10:100044045:T:C|rs555032946|      T2D| 0.928|191764.0|\n|10:100061414:T:C| rs76589250|      T2D|0.5835|  4347.0|\n|10:100108558:G:A|rs139361990|      T2D|  0.23|442817.0|\n+----------------+-----------+---------+------+--------+\nonly showing top 5 rows\n\n"
    }
   ],
   "source": [
    "# join the dbSNP id with the associations\n",
    "df_joined = df_variant_load.join(df_phenotype_load, 'varId', how='inner')\n",
    "\n",
    "# print\n",
    "print(\"the loaded joined data frame has {} rows\".format(df_joined.count()))\n",
    "df_joined.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "the list of phenotypes is ['T2D', 'AF']\n"
    }
   ],
   "source": [
    "# get the distinct phenotypes\n",
    "df_unique_phenotype = df_joined.select('phenotype').distinct().rdd.map(lambda r: r[0]).collect()\n",
    "\n",
    "print(\"the list of phenotypes is {}\".format(df_unique_phenotype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37664bittf237venv9b274482c7ba4966ad2cf02baa9bb24c",
   "display_name": "Python 3.7.6 64-bit ('tf2_37': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}